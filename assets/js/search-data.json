{
  
    
        "post0": {
            "title": "脳が対側支配をする進化的な利点は何か",
            "content": "神経解剖を学ぶと、次のような疑問は自然と生じると思います。それは「なぜ脳では対側支配(contralateral innervation)があるのか」というものです。ここでの対側とは、身体の正中線に対し反対側のことを指します。例としては左運動野が右側の筋群を、右運動野 が 左側の筋群 を制御するといった対側制御(contralateral control)が挙げられます。何ともややこしい配線ですが、なぜ同側支配ではダメだったのでしょうか？対側支配をする利点はあるのでしょうか？ . かなり基本的な内容に対する疑問ではありますが、この問題はRamón y Cajalの1898年の論文に端を発します (Ramón y Cajal. 1898)。古くはHippocratesも、左頭部負傷が右の筋群の運動に影響を与えることを知っていたようです (Vulliemoz et al., Lancet Neurol. 2005)。しかしながら、神経科学の著名な教科書にもこれに対する明確な回答はありません (カンデル神経科学や神経科学-脳の探求-を一通りざっと見ただけですが)。幸い、英語でGoogle検索すると当然ながら同様の疑問を抱く人は多数いるようで、Quoraにおいていくつかの解答を見つけました (Why does our left hemisphere of brain control our right side of our body and the right our left? - Quora)。 . 【追記(2020/03/10)】WikipediaのContralateral brainのページとも内容が被っていることに気づきました。 . Quoraの記事で紹介されている論文を足掛かりに文献を調べた結果ですが、この問題に関する優れた総説として(Vulliemoz et al., Lancet Neurol. 2005; Mora et al., Neurosurg. Focus. 2019)があります。 . 本記事では、対側支配の神経解剖を復習しつつ、脳が対側支配をする進化的な利点の仮説を紹介していきます。なお、仮説ということを強調しているのはこれが進化的な話を含み、実験的証明が難しいためです。また、筆者は神経解剖学・神経発生学の教室でも研究をしていますが、本記事における内容に関しては全く研究していないのでご了承ください。 . 正中を横切る神経線維 . まず、正中を横切る神経線維は交叉(decussation)や交連(commissure)と言った名称がつけられています。ここではいくつかの経路を簡単にまとめましたが、詳しくは何処のご家庭にもある神経解剖の教科書を読みましょう (今回は寺島先生の神経解剖学講義ノートを参考にしました)。 . 視交叉(optic chiasma) . 視神経の交叉のことです。両生類、魚類、鳥類では視神経が完全に交叉します(完全交叉)が、ネコなどの食肉類や霊長類では50%の視神経のみが交叉します(半交叉)。 . 運動路における交叉 . 運動路で代表的なのが皮質脊髄路(corticospinal tract, CST; または錐体路とも)です。皮質脊髄路は主に運動性皮質L5の錐体細胞を起始とし、脊髄に終わる経路です。皮質脊髄路の途中で延髄腹側の錐体において神経線維が交叉しますが、これを錐体交叉(または運動交叉) (pyramidal decussation, motor decussation)と言います。錐体交叉では全ての神経が交叉するわけではないですが、交叉しなかった線維も脊髄の白交連(anterior white commissure)で最終的には交叉します。なので、皮質脊髄路線維は全て対側の運動ニューロンを支配することになります。他には赤核脊髄路 (rubrospinal tract)における腹側被蓋交叉(tegmental decussation)や、視蓋脊髄路 (tectospinal tract)における背側被蓋交叉(dorsal tegmental decussation)があります。 . 感覚路における交叉 . 感覚路も色々ありますが、頭部以外の体性感覚の伝導路であれば後索・内側毛帯系と脊髄視床路系があります。後索・内側毛帯系では毛帯交叉(sensory decussation, decussation of the lemniscus)、脊髄視床路系では脊髄の白交連を経由して対側の体性感覚野に至ります。 . 小脳の経路における交叉 . 念のため触れておきます。まず、小脳は同側支配です。例えば右小脳半球外側部を損傷すると、右側 (患側)に小脳性運動失調が現れます。この理由は、小脳からの出力線維が交叉しない(例えば非交叉性室頂核前庭線維)か、2回交叉するためです。2回交叉は裏の裏が表になるのと同じことで、例えば上記の症例における経路は、小脳半球外側部から視床VL核までで上小脳脚交叉があり、視床から大脳皮質は交叉無し、大脳皮質から皮質脊髄路の錐体交叉でもう一度交叉する、となっています。 . 神経線維の交叉に関連した疾患 . 神経系の発生においては軸索誘導分子(axon guidance molecules)の寄与が必要ですが、それらをコードする遺伝子に異常が生じると神経発生が正常に行われなくなります。そのような疾患の例として、クリッペル・ファイル症候群(Klippel-Feil syndrome)、 X連鎖性カルマン症候群(X-linked Kallmann’s syndrome)などでは非交叉性の皮質遠心性線維が形成されることで鏡像運動(mirror movements; 随意的な運動を行うときに、対側にも不随意的に運動が生じる症状)が生じます (Comer et al., Neural Dev. 2019)。しかしながら病態機序はいくつか考えられるようなので、詳細は書きません (cf. 脳科学辞典の鏡像運動の項目)。 . Ramón y Cajalの仮説 . この節は、Ramón y Cajalの仮説についての説明をします。なお、Cajalの発表の後となりますが英国の医師であったFrancis DixonもCajalと類似の説を提唱しています(Dixon, The Dublin Journal of Medical Science. 1907; Dixon, The Dublin Journal of Medical Science. 1918)。 . さて、Cajalの視交叉についての仮説は、脳内での外界の連続性を維持するためには交叉が必要である、ということです。次図は前方に眼があり視交叉が無い生物が矢を見た場合の図です。網膜で外界が反転されるため、交叉が無いと矢尻と矢羽が繋がった像となります。そのため、2つの視野像から脳内で外界を復元するには像を交叉させる必要があります。 . . (Ramón y Cajal. 1898; 図の間接的な引用元は Ramón Y Cajal. Histología del sistema nervioso del hombre y de los vertebrados. Tomo II. Segunda parte. 2012) . 次図の上部は、前述の通り視交叉により外界が正しく復元されることを示しています。また、完全な交叉ではない半交叉であることが立体視に重要であることも指摘していました。Cajalはさらに説を広げ、運動路と感覚路に交叉がある理由も視交叉と関連付けました。これが対側支配におけるCajalの仮説です。次図中央部では連続した外界が復元されていますが、このままでは像が反転しています。Cajalは視野の右側を体の右側と、視野の左側を体の左側と一致させるために、運動路と体性感覚路を交叉させる必要があると主張しました。 . . (Ramón y Cajal. 1898) . しかし、Cajalの仮説は完全に誤っているわけではないものの、いくつかの問題点があることが指摘されています (de Lussanet &amp; Osse, Animal Biol. 2012)。まず、視交叉の説について、眼球は動くため、網膜像も動きます。そのため、位置合わせを完全に正確にすることはできません (予測により補間はしていると思われるので、Cajalが間違っているとは言えませんが)。次に、運動路と感覚路を関連させた説については、同側の視覚情報・感覚情報のみが運動野に至るというのは最適ではないということです。運動することを考えれば、両側の情報を統合して座標系を生み出した方がよいでしょうし、実際に脳はそうしています。 . ということで、Cajalの仮説は完全に誤りではないにせよ、間違っている点も見られるということになります。ただ、Cajalが偉大だったことに変わりはないなと、今回スケッチを見直して思いました。 . ねじれ仮説 (twist hypothesis) . 無脊椎動物から脊椎動物へ至る間に体のねじれが生じた、というのがねじれ仮説 (twist hypothesis) です。これは対側支配が生じた目的ではなく、その過程についての仮説となっています。 . ねじれ仮説には(Kinsbourne, Neuropsychology. 2013)の体性ねじれ説 (somatic twist hypothesis) と、(de Lussanet &amp; Osse, Animal Biol. 2012)の軸ねじれ説 (axial twist hypothesis) の2つが提案されています。まず、Kinsbourneの体性ねじれ説は、180度の回転が一回起こった、というものです。一方で、de LussanetとOsseの軸ねじれ説は2つの90度の回転が起こった、というものです。両者の差異は分かりづらいですが、de LussanetとOsseによって解説されています (de Lussanet &amp; Osse, Neuropsychology. 2015)。 . . (de Lussanet &amp; Osse, Neuropsychology. 2015, Fig.1) . AはKinsbourneの体性ねじれ説を示しており、前口動物(Protostome)が脊椎動物(vertebrate)へと進化するに伴い、前脳と眼の領域が180度回転したことを表します。Bはde LussanetとOsseの軸ねじれ説で、黒線が背側、白線が腹側、点は眼となる領域、ovはoptic vesicleを意味します。重要なのはB2で、前脳と眼の領域が90度の時計回り、中脳より下が90度の反時計回りをすることで合計で180度のねじれが生まれます。 . どちらの仮説も視交叉や、交叉しない嗅覚経路、および小脳の同側支配などを説明します。しかし、de LussanetとOsseは軸ねじれ説であれば、心臓や腸管などの臓器が左右対称ではないこと、などが説明できると主張しています。また、両者の説の弱いところとして視交叉などでの全交叉は説明しても、一部の神経が同側に向かう半交叉は説明できない、といった点を挙げています。 . いずれにせよ、進化の過程で何らかのねじれが生じたことは誤りではないでしょうが、何故そのねじれが保存されてきたのでしょうか？やはり、そこには対側支配の利点があったのでしょう。次節からは対側支配(主に皮質脊髄路や赤核脊髄路の運動制御、脊髄視床路の体性感覚)の進化的利点についての仮説を見ていきます。 . 回避行動仮説 (avoidance behavior hypothesis) . 危険な刺激を知覚し回避行動を取るために体の構造の進化に伴って交叉が必要となった、というのが回避行動仮説 (avoidance behavior hypothesis) です (Vulliemoz et al., Lancet Neurol. 2005)。 . . (Vulliemoz et al., Lancet Neurol. 2005, Fig.2) . まず、交叉が無く、手足も無い原始的な種の場合を考えます(図上部; なお図では魚のような見た目ですが、魚類の錐体路も交叉が存在するようです)。このような生物の場合、危険な刺激は右脳半球によって知覚され、右半身の筋肉の収縮を引き起こし、屈曲させることで危険を回避します。このとき、交叉していない原始的な経路 (網様体脊髄路や前庭脊髄路)を介して筋肉は制御されます。 . 一方で、四肢を持つ脊椎動物(図下部)は、左肢を伸ばすことにより、左側の刺激を回避しようとします。このとき、交叉のある(系統発生的に)新しい経路 (皮質脊髄路や赤核脊髄路)を介して筋肉は制御されます。 . 特に根拠についての記載はありませんでしたが、１つの説と言えます。 . 保護機構仮説 (protective mechanism hypothesis) . 対側支配であることは身体保護の観点で優れている、という説が保護機構仮説 (protective mechanism hypothesis) です (Whitehead &amp; Banihani, Laterality. 2014)。前節の回避行動仮説と体を守るという観点では似ていますが、少し異なります。これまでに紹介してきた論文と異なり、WhiteheadとBanihaniは中程度の損傷を受けた場合、対側支配の方が生存しやすいことを簡単な数理モデルを用いて説明しています。ここでは数理モデルの紹介は省略し、簡単なお気持ちだけ説明します。 . ここでは、生物の体が左右の脳半球(と神経)及び左右の筋群の4つから成ると考えます。両半身を損傷すると致命的となることが多いですが、片半身だけの損傷であれば生存することも可能です。このとき、例えば右脳半球と左筋群の組み合わせが損傷を受けることはあまりなく、どちらかというと転倒や衝突により片側の脳半球と筋群が傷害されやすいでしょう。 . 同側支配の場合、片側の脳半球と筋群が同時に損傷を受けると、損傷を受けた半球と損傷を受けた筋群という組み合わせにより片側は完全に動かすことができなくなります。一方で対側支配の場合、各脳半球は反対側を制御するため、例えば右半身を損傷した場合は、損傷した右半身を制御する無傷の左脳半球と、無傷の左側を制御する損傷した右脳半球という状況になります。無傷の左半球は損傷しているとは言え、一部の右側の筋群を動かすことができるでしょう。また、損傷した右半球であっても左側の筋群は無事であるためにある程度は制御できるでしょう。 . 片側が完全に機能しない場合に比べ、両側に影響はあるものの何とか動かすことができる場合の方が生存しやすいと仮定すると、交叉が保存されてきたことにも納得できます。 . まとめ . 本記事では主に運動野と感覚野の対側支配がどのように生じたのか、また何故対側支配が保存されてきたのか、ということについての仮説を見てきました (重ねて言いますが仮説止まりです)。現在提案されている説をまとめると、体がねじれることで対側支配が生まれ、それが生存にとって有利であったために保存されてきた、と言えます。冒頭に述べたように、進化が絡むと直接的な証拠というものを見つけづらいとは思いますが (他の研究例を知らないだけかもしれませんが)、将来は何らかの説に落ち着くのではないか、と思っています。 . 参考文献 . Carson RG. Neural pathways mediating bilateral interactions between the upper limbs. Brain Res Rev. 2005;49(3):641–662. doi:10.1016/j.brainresrev.2005.03.005 https://www.sciencedirect.com/science/article/abs/pii/S0165017305000482?via%3Dihub . | Comer JD, Alvarez S, Butler SJ, Kaltschmidt JA. Commissural axon guidance in the developing spinal cord: from Cajal to the present day. Neural Dev. 2019;14(1):9. doi:10.1186/s13064-019-0133-1 . | . https://neuraldevelopment.biomedcentral.com/articles/10.1186/s13064-019-0133-1 . de Lussanet MH, Osse JW. Decussation as an axial twist: A comment on Kinsbourne (2013). Neuropsychology. 2015;29(5):713–714. doi:10.1037/neu0000163 | . https://peerj.com/preprints/432.pdf . de Lussanet, MH, Osse, JW. An ancestral axial twist explains the contralateral forebrain and the optic chiasm in vertebrates. Animal Biol. 2012; 62: 193-216. doi:10.1163/157075611X617102. | . https://arxiv.org/abs/1003.1872 . Dixon AF. Why are the great motor and sensory tracts of the central nervous system crossed?. The Dublin Journal of Medical Science. 1907; 124, 1–4. doi:10.1007/BF02972358 | . https://link.springer.com/article/10.1007/BF02972358 . Dixon AF. Why are the cerebral motor and sensory cortical areas arranged in an inverted order?. The Dublin Journal of Medical Science. 1918; 145, 154–160. doi:10.1007/BF02958527 https://link.springer.com/article/10.1007%2FBF02958527 . | Kinsbourne M. Somatic twist: a model for the evolution of decussation. Neuropsychology. 2013;27(5):511–515. doi:10.1037/a0033662 https://www.semanticscholar.org/paper/Somatic-twist%3A-a-model-for-the-evolution-of-Kinsbourne/fe2d36ddc63af9f26aa22ec1bbce115f7aa35387 . | Loosemore RG. The inversion hypothesis: A novel explanation for the contralaterality of the human brain. Biosci Hypotheses. 2009;2:375–382 . | . https://www.sciencedirect.com/science/article/abs/pii/S1756239209001347 . Mora C, Velásquez C, Martino J. The neural pathway midline crossing theory: a historical analysis of Santiago Rámon y Cajal’s contribution on cerebral localization and on contralateral forebrain organization. Neurosurg Focus. 2019;47(3):E10. doi:10.3171/2019.6.FOCUS19341 | . https://thejns.org/focus/view/journals/neurosurg-focus/47/3/article-pE10.xml . Ramón y Cajal, S. Estructura del kiasma óptico y teoría general de los entrecruzamientos de las vías nerviosas. 1898. [german 1899, english 2004]. Rev. Trim. Microgràfica 3, 15–65. . | Ramón Y Cajal, S. Histología del sistema nervioso del hombre y de los vertebrados. Tomo II. Segunda parte. Boletín Oficial del Estado. 2012. https://digital.csic.es/bitstream/10261/158606/1/Cap%C3%ADtulo32-T2-2%C2%AA%20parte.pdf . | Shinbrot T, Young W. Why decussate? Topological constraints on 3D wiring. Anat Rec (Hoboken). 2008;291(10):1278–1292. doi:10.1002/ar.20731 . | . https://anatomypubs.onlinelibrary.wiley.com/doi/full/10.1002/ar.20731 . Vulliemoz S, Raineteau O, Jabaudon D. Reaching beyond the midline: why are human brains cross wired?. Lancet Neurol. 2005;4(2):87–99. doi:10.1016/S1474-4422(05)00990-7 | . https://www.thelancet.com/journals/laneur/article/PIIS1474-4422(05)00990-7/fulltext . Welniarz Q, Dusart I, Roze E. The corticospinal tract: Evolution, development, and human disorders. Dev Neurobiol. 2017;77(7):810–829. doi:10.1002/dneu.22455 | . https://onlinelibrary.wiley.com/doi/abs/10.1002/dneu.22455 . Whitehead L, Banihani S. The evolution of contralateral control of the body by the brain: is it a protective mechanism?. Laterality. 2014;19(3):325–339. doi:10.1080/1357650X.2013.824461 | . https://www.researchgate.net/publication/255732556_The_evolution_of_contralateral_control_of_the_body_by_the_brain_Is_it_a_protective_mechanism .",
            "url": "https://salad-bowl-of-knowledge.github.io/hp/neuroscience/2020/03/07/contralateral_brain.html",
            "relUrl": "/neuroscience/2020/03/07/contralateral_brain.html",
            "date": " • Mar 7, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://salad-bowl-of-knowledge.github.io/hp/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Pythonによる分位点回帰 (Quantile regression)",
            "content": "Distributional Reinforcement Learningの理解のために必要だったのでメモとして残しておきます (本当はexpectile regressionも書かなければならないですが)。内容としてはNumpyで勾配法により分位点回帰をする、というものになっています。 . &#20998;&#20301;&#28857;&#22238;&#24112; (Quantile Regression)&#12392;&#12399; . 通常の最小二乗法による線形回帰(Ordinary least squares regression)は、誤差が正規分布と仮定したときのX(説明変数)に対するY(目的変数)の期待値E[Y]を求めます。これに対して分位点回帰(quantile regression)では、Xに対するYの分布における分位点を通るような直線を引きます。 . 分位点(または分位数)についてですが、簡単なのが四分位数です。箱ひげ図などで出てきますが、例えば第一四分位数は分布を25:75に分ける数、第二四分位数(中央値)は分布を50:50に分ける数です。同様に$q$分位数($q$-quantile)というと分布を$q:1-q$に分ける数となっています。 . さて、分位点回帰に戻りましょう。下図は$x sim U(0, 5), quad y=3x+x cdot xi, quad xi sim N(0,1)$とした500個の点に対する分位点回帰です(コードは図の下にあります)。青い領域はX=1,2,3,4でのYの分布を示しています。紫、緑、黄色の直線はそれぞれ10, 50, 90%tile回帰の結果です。例えば50%tile回帰の結果は、Xが与えられたときのYの中央値(50%tile点)を通るような直線となっています。同様に90%tile回帰の結果は90%tile点を通るような直線となっています。 . #collapse-hide import numpy as np np.random.seed(0) from matplotlib import pyplot as plt from tqdm import tqdm def QuantileGradientDescent(X, y, init_theta, tau, lr=1e-4, num_iters=10000): theta = init_theta for i in range(num_iters): y_hat = X @ theta # predictions delta = y - y_hat # error indic = np.array(delta &lt;= 0., dtype=np.float32) # indicator grad = np.abs(tau - indic) * np.sign(delta) # gradient theta += lr * X.T @ grad # Update return theta def gaussian_func(x, mu, sigma): return (0.8/sigma)*np.exp( - (x - mu)**2 / (2 * sigma**2)) cmap = plt.cm.viridis(np.linspace(0., 1., 3)) # Generate Toy datas N = 500 # sample size x = np.random.rand(N)*5 y = 3*x + x*np.random.randn(N) X = np.ones((N, 2)) # design matrix X[:, 1] = x taus = np.array([0.1, 0.5, 0.9]) m = len(taus) Y = np.zeros((m, N)) # memory array for i in tqdm(range(m)): init_theta = np.zeros(2) # init variables theta = QuantileGradientDescent(X, y, init_theta, tau=taus[i]) y_hat = X @ theta Y[i] = y_hat # Results plot plt.figure(figsize=(5,4)) plt.title(&quot;Quantile Regression&quot;) plt.scatter(x, y, color=&quot;gray&quot;, s=5) # samples for i in range(m): plt.plot([min(x), max(x)], [min(Y[i]), max(Y[i])], linewidth=2, color=cmap[i], label=str(int(taus[i]*100))+&quot;%tile&quot;) # regression line for loc in range(1,5): noise_y = np.arange(0, 6*loc, 1e-3) noise_x = loc + gaussian_func(noise_y, 3*loc, loc) plt.fill_between(noise_x, -1, noise_y, color=&#39;#539ecd&#39;, linewidth=2, alpha=0.5) plt.plot(noise_x, noise_y, color=&#39;#539ecd&#39;, linewidth=2) plt.xlabel(&quot;x&quot;) plt.ylabel(&quot;y&quot;) plt.ylim(0, 25) plt.legend() plt.tight_layout() plt.show() . . 100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00&lt;00:00, 7.67it/s] . 分位点回帰の利点としては、外れ値に対して堅牢(ロバスト)である、Yの分布が非対称である場合にも適応できる、などがあります (Das et al., Nat Methods. 2019)。 . それでは分位点回帰をPythonで行う方法を見ていきましょう。 . &#21246;&#37197;&#27861;&#12395;&#12424;&#12427;&#32218;&#24418;&#22238;&#24112; (&#26368;&#23567;&#20108;&#20055;&#27861;) . 最小二乗法による線形回帰と異なり、分位点回帰は解析的に求めることができません。そのため、数値的に勾配法で求めるのですが、一先ずは最小二乗法による回帰直線を勾配法で求めてみましょう。 . 簡単のために単回帰の場合を考えます。パラメータを$ theta in mathbb{R}^2$, サンプルサイズを$n$, 説明変数の計画行列を$n times 2$の行列$X$, 目的変数を$y in mathbb{R}^n$とします。ただし$X$と$y$は観測値です。$y$の予測値は$X theta$なので、誤差 $ delta in mathbb{R}^n$は $$ delta = y-X theta$$ と表せます (符号は逆のことが多いですが)。最小二乗法において最適化したい目的関数は$$L( delta)= sum_{i=1}^n delta_i^2 = | delta |^2= delta^T delta$$ であり、$$ frac{ partial L}{ partial theta}=- frac{1}{n} delta X$$ と表せるので、$ theta$の更新式は$ theta leftarrow theta + alpha cdot dfrac{1}{n} delta X$と書けます ($ alpha$は学習率です)。 . さて、これを実装したコードと結果は次のようになります。 . #collapse-hide # Ordinary least squares regression def OLSRegGradientDescent(X, y, init_theta, lr=1e-4, num_iters=10000): theta = init_theta for i in range(num_iters): y_hat = X @ theta # predictions delta = y - y_hat # error theta += lr * delta @ X # Update return theta # Generate Toy datas N = 500 # sample size x = np.linspace(0, 10, N) y = 3*x + x*np.random.randn(N) X = np.ones((N, 2)) # design matrix X[:, 1] = x # Gradient descent init_theta = np.zeros(2) # init variables lr = 1e-4 # learning rate num_iters = 1000 # training iterations theta = OLSRegGradientDescent(X, y, init_theta) y_hat = X @ theta # predictions # Results plot plt.figure(figsize=(5,4)) plt.title(&quot;Least Squares Regression&quot;) plt.scatter(x, y, color=&quot;gray&quot;, s=5) # samples plt.plot([min(x), max(x)], [min(y_hat), max(y_hat)], color=&#39;red&#39;) # regression line plt.xlabel(&quot;x&quot;) plt.ylabel(&quot;y&quot;) plt.tight_layout() plt.show() . . 上図において赤色の線が回帰直線です。今回は誤差を正規分布としているので綺麗な結果ですが、実際には外れ値の影響を受けたりします。 . &#21246;&#37197;&#27861;&#12395;&#12424;&#12427;&#20998;&#20301;&#28857;&#22238;&#24112; . 本題の分位点回帰です。前節と同様の設定とします。ここで $ delta$の関数を $$ rho_{ tau}( delta)= left| tau- mathbb{I}_{ delta leq 0} right| cdot | delta|= left( tau- mathbb{I}_{ delta leq 0} right) cdot delta$$ とします。ただし、$ tau$は関心のある分位点(quantile)、$ mathbb{I}$は指示関数(indicator function)です。この場合、$ mathbb{I}_{ delta leq 0}$は$ delta gt 0$なら0, $ delta leq 0$なら1となります。このとき、分位点回帰の目的関数は $$L_{ tau}( delta) = sum_{i=1}^n rho_{ tau}( delta_i)$$ です。なぜこの目的関数の最適化が$ tau$-分位点の回帰となるかについてはQuantile regressionのWikipediaに詳細に書いてあります。また、$ rho_{ tau}( delta)$を色々な $ tau$についてplotすると次図のようになります。 . #collapse-hide delta = np.arange(-5, 5, 0.1) tau= np.arange(0.2, 1.0, 0.2) cmap = plt.cm.brg(np.linspace(0, 0.5, len(tau))) plt.figure(figsize=(4,3)) for i in range(len(tau)): indic = delta &lt;= 0 y = (tau[i]-indic)*delta plt.plot(delta, y, label=r&quot;$ tau=$&quot;+&quot;{0:.1f}&quot;.format(tau[i]), color=cmap[i]) plt.xlabel(&quot;Error&quot;) plt.ylabel(&quot;Loss&quot;) plt.legend() plt.tight_layout() plt.show() . . それでは$L_ tau$を最小化するような$ theta$の更新式について考えていきましょう。まず、$$ frac{ partial rho_{ tau}( delta)}{ partial delta}= rho_{ tau}^{ prime}( delta)= left| tau- mathbb{I}_{ delta leq 0} right| cdot operatorname{sign}( delta)$$ です (ただしsignは符号関数)。さらに$$ frac{ partial L_{ tau}}{ partial theta}= frac{ partial L_{ tau}}{ partial delta} frac{ partial delta( theta)}{ partial theta}=- frac{1}{n} rho_{ tau}^{ prime}( delta) X$$ が成り立つので、$ theta$の更新式は$ theta leftarrow theta + alpha cdot dfrac{1}{n} rho_{ tau}^{ prime}( delta) X$と書けます ($ alpha$は学習率です)。ゆえに実装には前節のコードを少し修正すればよいです。 . #collapse-hide def QuantileRegGradientDescent(X, y, init_theta, tau, lr=1e-4, num_iters=10000): theta = init_theta for i in range(num_iters): y_hat = X @ theta # predictions delta = y - y_hat # error indic = np.array(delta &lt;= 0., dtype=np.float32) # indicator grad = np.abs(tau - indic) * np.sign(delta) # gradient theta += lr * grad @ X # Update return theta cmap = plt.cm.viridis(np.linspace(0., 1., 5)) # Generate Toy datas N = 500 # sample size x = np.random.rand(N)*5 y = 3*x + x*np.random.randn(N) X = np.ones((N, 2)) # design matrix X[:, 1] = x taus = np.array([0.01, 0.1, 0.5, 0.9, 0.99]) m = len(taus) Y = np.zeros((m, N)) # memory array for i in tqdm(range(m)): init_theta = np.zeros(2) # init variables theta = QuantileRegGradientDescent(X, y, init_theta, tau=taus[i]) y_hat = X @ theta # prediction Y[i] = y_hat # memory # Results plot plt.figure(figsize=(5,4)) plt.title(&quot;Quantile Regression&quot;) plt.scatter(x, y, color=&quot;gray&quot;, s=5) # samples for i in range(m): plt.plot([min(x), max(x)], [min(Y[i]), max(Y[i])], linewidth=2, color=cmap[i], label=r&quot;$ tau=$&quot;+str(taus[i])) # regression line plt.xlabel(&quot;x&quot;) plt.ylabel(&quot;y&quot;) plt.legend() plt.tight_layout() plt.show() . . 100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00&lt;00:00, 7.95it/s] . ただし、分位点回帰を単純な勾配法で求める場合、勾配が0となって解が求まらない可能性があるので避けた方が良いという話はあります。そのために、目的関数を滑らかにするという研究もあります (Zheng. IJMLC. 2011)。 . Statsmodels&#12395;&#12424;&#12427;&#20998;&#20301;&#28857;&#22238;&#24112; . 前節のように分位点回帰は実装できますが、より簡単かつ高速に行うにはライブラリを用いるのがよいです。Statsmodelには分位点回帰のモデルがあり、それを最適化するだけで回帰直線が得られます。 . #collapse-hide import statsmodels.api as sm from statsmodels.regression.quantile_regression import QuantReg cmap = plt.cm.viridis(np.linspace(0., 1., 5)) # Generate Toy datas N = 500 # sample size x = np.random.rand(N)*5 y = 3*x + x*np.random.randn(N) X = sm.add_constant(x) model = QuantReg(y, X) taus = np.array([0.01, 0.1, 0.5, 0.9, 0.99]) m = len(taus) Y = np.zeros((m, N)) # memory array for i in range(m): results = model.fit(q=taus[i]) y_hat = X @ results.params Y[i] = y_hat plt.figure(figsize=(5,4)) plt.scatter(x, y, color=&quot;gray&quot;, s=5) # samples for i in range(m): plt.plot([min(x), max(x)], [min(Y[i]), max(Y[i])], linewidth=2, color=cmap[i], label=r&quot;$ tau=$&quot;+str(taus[i])) # regression line plt.xlabel(&quot;x&quot;) plt.ylabel(&quot;y&quot;) plt.legend() plt.tight_layout() plt.show() . . &#21442;&#32771;&#25991;&#29486; . https://en.wikipedia.org/wiki/Quantile_regression | Das, K., Krzywinski, M. &amp; Altman, N. Quantile regression. Nat Methods 16, 451–452 (2019) doi:10.1038/s41592-019-0406-y | Quantile and Expectile Regressions (pdf) | .",
            "url": "https://salad-bowl-of-knowledge.github.io/hp/statistics/2020/01/21/quantile_regression.html",
            "relUrl": "/statistics/2020/01/21/quantile_regression.html",
            "date": " • Jan 21, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Distributional Reinforcement Learningの仕組み",
            "content": "この記事は(Dabney, et al., Nature. 2020)におけるDistributional Reinforcement Learningを実装しながら理解しようという内容です。解説とか言うのは恐れ多いので自分用のメモだと思ってください…。また、どちらかというと神経科学寄りの内容です(深層強化学習への応用については触れません)。 . この研究はDeepMindとHarvardの内田先生のラボの共同研究で、アニメーション付きの解説記事をDeepMindが書いています (DeepMindのブログ)。Botvinick氏と内田先生の講演をCiNetで聞いたにも関わらず理解が疎かだったのですが、論文が公開されたので、ちゃんと理解しておこうという次第です。また、コード(MATLAB, Python)も公開されており(https://doi.org/10.17605/OSF.IO/UX5RG) 、この記事ではこのコードをかなり参考にしています。 . Classical TD learning vs Distributional TD learning . Classical TD learning . TD (Temporal difference) learningにおいて、報酬予測誤差(reward prediction error, RPE) $ delta_{i}$は次のように計算されます (この式はDistributional TD learningでも共通です)。 $$ delta_{i}=r+ gamma V_{j} left(x^{ prime} right)-V_{i}(x) $$ ただし、現在の状態を$x$, 次の状態を$x&#39;$, 予測価値分布を$V(x)$, 報酬信号を$r$, 時間割引率(time discount)を$ gamma$としました。 また、$V_{j} left(x^{ prime} right)$は予測価値分布$V left(x^{ prime} right)$からのサンプルです。 このRPEは脳内において主に中脳のVTA(腹側被蓋野)やSNc(黒質緻密部)におけるドパミン(dopamine)ニューロンの発火率として表現されています。 . ただし、VTAとSNcのドパミンニューロンの役割は同一ではありません。ドパミンニューロンへの入力が異なっています (Watabe-Uchida et al., Neuron. 2012)00281-4)。 また、細かいですがドパミンニューロンの発火は報酬量に対して線形ではなく、やや飽和する非線形な応答関数 (Hill functionで近似可能)を持ちます(Eshel et al., Nat. Neurosci. 2016)。このため著者実装では報酬 $r$に非線形関数がかかっているものもあります。 . 先ほどRPEはドパミンニューロンの発火率で表現されている、といいました。RPEが正の場合はドパミンニューロンの発火で表現できますが、単純に考えると負の発火率というものはないため、負のRPEは表現できないように思います。ではどうしているかというと、RPEが0（予想通りの報酬が得られた場合）でもドパミンニューロンは発火しており、RPEが正の場合にはベースラインよりも発火率が上がるようになっています。逆にRPEが負の場合にはベースラインよりも発火率が減少する(抑制される)ようになっています (Schultz et al., Science. 1997; Chang et al., Nat Neurosci. 2016)。発火率というのを言い換えればISI (inter-spike interval, 発火間隔)の長さによってPREが符号化されている(ISIが短いと正のRPE, ISIが長いと負のRPEを表現)ともいえます (Bayer et al., J. Neurophysiol. 2007)。 . 予測価値(分布) $V(x)$ですが、これは線条体(striatum)のパッチ (SNcに抑制性の投射をする)やVTAのGABAニューロン (VTAのドパミンニューロンに投射して減算抑制をする, (Eshel, et al., Nature. 2015))などにおいて表現されています。 この予測価値は通常のTD learningでは次式により更新されます。 $$ V_{i}(x) leftarrow V_{i}(x)+ alpha_{i} f left( delta_{i} right) $$ ただし、$ alpha_{i}$は学習率(learning rate), $f( cdot)$はRPEに対する応答関数です。生理学的には$f( delta)= delta$を使うのが妥当ですが、後の分位数(quantile)モデルでは$f( delta)= text{sign}( delta)$を用います。 . Distributional TD learning . Distributional TD learningではRPEの正負に応じて、予測報酬の更新を異なる学習率($ alpha_{i}^{+}, alpha_{i}^{-}$)を用いて行います。 $$ begin{cases} V_{i}(x) leftarrow V_{i}(x)+ alpha_{i}^{+} f left( delta_{i} right) &amp; text{for } delta_{i} gt 0 V_{i}(x) leftarrow V_{i}(x)+ alpha_{i}^{-} f left( delta_{i} right) &amp; text{for } delta_{i} leq 0 end{cases} $$ ここで、シミュレーションにおいては$ alpha_{i}^{+}, alpha_{i}^{-} sim U(0, 1)$とします($U$は一様分布)。さらにasymmetric scaling factor $ tau_i$を次式により定義します。 $$ tau_i= frac{ alpha_{i}^{+}}{ alpha_{i}^{+}+ alpha_{i}^{-}} $$ なお、$ alpha_{i}^{+}, alpha_{i}^{-} in [0, 1]$より$ tau_i in [0,1]$です。 . Classical TD learningとDistributional TD learningにおける各ニューロンのRPEに対する発火率を表現したのが次図となります。 . #collapse-hide import numpy as np from matplotlib import pyplot as plt # Classical TD learning N = 10 cmap = plt.cm.brg(np.linspace(0, 0.5, N)) x = np.arange(-1, 1, 1e-2)[:, None] theta = np.linspace(np.pi/6, np.pi/3, N) alpha = np.tan(theta) y = alpha * x # Plot plt.figure(figsize=(8, 4)) def hide_ticks(): #上と右の軸を表示しないための関数 plt.gca().spines[&#39;right&#39;].set_visible(False) plt.gca().spines[&#39;top&#39;].set_visible(False) plt.gca().yaxis.set_ticks_position(&#39;left&#39;) plt.gca().xaxis.set_ticks_position(&#39;bottom&#39;) plt.subplot(1,2,1) plt.axvline(x=0, color=&quot;gray&quot;, linestyle=&quot;dashed&quot;, linewidth=2) plt.axhline(y=0, color=&quot;gray&quot;, linestyle=&quot;dashed&quot;, linewidth=2) for i in range(N): if i == N//2: plt.plot(x, y[:, i], color=cmap[N//2], alpha=1, linewidth=3, label=&quot;Neutral&quot;) else: plt.plot(x, y[:, i], color=cmap[N//2], alpha=0.2) hide_ticks() plt.ylim(-1,1); plt.xlim(-1,1) plt.xticks([]); plt.yticks([]) plt.legend(loc=&#39;upper left&#39;) plt.title(&quot;Classical TD learning&quot;) plt.xlabel(&quot;RPE&quot;) plt.ylabel(&quot;Firing&quot;) # Distributional TD learning N = 20 cmap = plt.cm.brg(np.linspace(0, 0.5, N)) x = np.arange(-1, 1, 1e-2)[:, None] theta = np.linspace(np.pi/16, np.pi*7/16, N) alpha_pos = np.tan(theta) alpha_neg = np.tan(theta)[::-1] y = (alpha_pos*(x&gt;0) + (alpha_neg)*(x&lt;=0))*x # Plot ax = plt.subplot(1,2,2) plt.axvline(x=0, color=&quot;gray&quot;, linestyle=&quot;dashed&quot;, linewidth=2) plt.axhline(y=0, color=&quot;gray&quot;, linestyle=&quot;dashed&quot;, linewidth=2) for i in range(N): if i == 0: plt.plot(x, y[:, i], color=cmap[i], alpha=1, linewidth=3, label=&quot;Pessimistic&quot;) elif i == N//2: plt.plot(x, y[:, i], color=cmap[i], alpha=1, linewidth=3, label=&quot;Neutral&quot;) elif i == N-1: plt.plot(x, y[:, i], color=cmap[i], alpha=1, linewidth=3, label=&quot;Optimistic&quot;) else: plt.plot(x, y[:, i], color=cmap[i], alpha=0.2) hide_ticks() handles, labels = ax.get_legend_handles_labels() ax.legend(reversed(handles), reversed(labels), loc=&#39;upper left&#39;) plt.ylim(-1,1); plt.xlim(-1,1) plt.xticks([]); plt.yticks([]) plt.title(&quot;Distributional TD learning&quot;) plt.xlabel(&quot;RPE&quot;) plt.ylabel(&quot;Firing&quot;) plt.show() . . Classical TD learningではRPEに比例して発火する細胞しかありませんが、Distributional TD learningではRPEの正負に応じて発火率応答が変化していることがわかります。 特に$ alpha_{i}^{+} gt alpha_{i}^{-}$の細胞を楽観的細胞 (optimistic cells)、$ alpha_{i}^{+} lt alpha_{i}^{-}$の細胞を悲観的細胞 (pessimistic cells)と著者らは呼んでいます。実際には2群に分かれているわけではなく、gradientに遷移しています。楽観的・悲観的の意味に関しては後でも触れますが、ここではイメージだけお伝えしておきます。まず楽観的細胞ではRPEが正なら「結構もらえるやん」、RPEが負なら「まあそういうときもあるよね」となり最終的な予測価値は通常よりも高くなります。逆に悲観的細胞ではRPEが正なら「もらえたけどいつもそうではないやろ」、RPEが負なら「やっぱあんまもらえんよな」となり最終的な予測価値は通常よりも低くなります。収束する予測価値が細胞ごとに異なることで、$V$には報酬の期待値ではなく複雑な形状の報酬分布が符号化されます。その仕組みについて、次節から見ていきます。 . &#20998;&#20301;&#25968;(Quantile)&#12514;&#12487;&#12523;&#12392;&#22577;&#37228;&#20998;&#24067;&#12398;&#31526;&#21495;&#21270; . RPE&#12395;&#23550;&#12377;&#12427;&#24540;&#31572;&#12364;sign&#38306;&#25968;&#12398;&#12514;&#12487;&#12523;&#12392;&#22577;&#37228;&#20998;&#24067;&#12398;&#20998;&#20301;&#28857;&#12408;&#12398;&#20104;&#28204;&#20385;&#20516;&#12398;&#21454;&#26463; . さて、Distributional RLモデルでどのようにして報酬分布が学習されるかについてみていきます。この節ではRPEに対する応答関数$f( cdot)$が符合関数(sign function)の場合を考えます。結論から言うと、この場合はasymmetric scaling factor $ tau_i$は分位数(quantile)となり、予測価値 $V_i$は報酬分布の$ tau_i$分位数に収束します。 . どういうことかを簡単なシミュレーションで見てみましょう。今、報酬分布を平均2, 標準偏差5の正規分布とします (すなわち$r sim N(2, 5^2)$となります)。また、$ tau_i = 0.25, 0.5, 0.75 (i=1,2,3)$とします。このとき、3つの予測価値 $V_i (i=1,2,3)$はそれぞれ$N(2, 5^2)$の0.25, 0.5, 0.75分位数に収束します。下図はシミュレーションの結果です。左が$V_i$の変化で、右が報酬分布と0.25, 0.5, 0.75分位数の位置 (黒短線)となっています。対応する分位数に見事に収束していることが分かります。 . #collapse-hide import seaborn as sns from tqdm import tqdm from matplotlib import gridspec ############ ### init ### ############ response_func = lambda r: np.sign(r) # RPEの応答関数 num_cells = 3 # ニューロン(ユニット)の数 num_steps = 5000 # 訓練回数 base_lrate = 0.02 # ベースラインの学習率 reward_mu = 5 # 報酬の平均(正規分布) reward_sigma = 2 # 報酬の標準偏差(正規分布) distribution = np.zeros(num_cells) # 価値分布を記録する配列 dist_trans = np.zeros((num_steps, num_cells)) # 価値分布を記録する配列 alpha_pos = np.array([.1, .2, .3]) # RPEが正のときの学習率 alpha_neg = np.array([.3, .2, .1]) # RPEが負のときの学習率 tau = alpha_pos / (alpha_pos + alpha_neg) # Asymmetric scaling factor ############## # simulation # ############## for step in tqdm(range(num_steps)): # 25000 steps # 報酬がrandomに選ばれる reward = np.random.normal(reward_mu, reward_sigma, size=(1,)) # 報酬誤差(step毎に更新) reward応答をlinearとする delta = reward - distribution # (3, ) # deltaが負なら1, 正なら0 valence = np.array(delta &lt;= 0., dtype=np.float32) # (3, ) # 予測価値分布の更新 alpha = valence * alpha_neg + (1. - valence) * alpha_pos distribution += alpha * response_func(delta) * base_lrate dist_trans[step] = distribution # 予測価値分布変化の記録 ################ # Results plot # ################ steps = np.arange(num_steps) ylim = (0, 10) # y軸のlim gs = gridspec.GridSpec(1, 2, width_ratios=[1, 0.25]) plt.figure(figsize=(6,4)) plt.subplot(gs[0]) # 予測価値の変化 for i in range(num_cells): plt.plot(steps, dist_trans[:, i], label=str((i+1)*25)+&quot;%tile (&quot;+r&quot;$ tau=$&quot;+str((i+1)*0.25)+&quot;)&quot;) plt.title(&quot;Convergence of value prediction to n percentile of reward distribution&quot;) plt.xlim(0, num_steps) plt.ylim(ylim) plt.xlabel(&quot;Learning steps&quot;) plt.ylabel(&quot;Learned Value&quot;) plt.legend() # 報酬のサンプリング rewards = np.random.normal(reward_mu, reward_sigma, size=(1000,)) percentile = np.percentile(rewards, q=[25, 50, 75]) # 報酬の四分位数を取得 plt.subplot(gs[1]) # 報酬分布とその分位数 sns.kdeplot(rewards, bw=1, shade=True, vertical=True) sns.rugplot(percentile, color=&#39;k&#39;, lw=2, height=0.2, vertical=True) plt.title(&quot;Reward n distribution&quot;) plt.ylim(ylim) plt.xlabel(&quot;Density&quot;) plt.tight_layout() plt.show() . . 100%|███████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00&lt;00:00, 79574.72it/s] . ここでoptimisticな細胞($ tau=0.75$)は中央値よりも高い予測価値、pessimisticな細胞($ tau=0.25$)は中央値よりも低い予測価値に収束しています。 つまり細胞の楽観度というものは、細胞が期待する報酬が大きいほど上がります。 . 同様のシミュレーションを今度は200個の細胞 (ユニット)で行います。報酬は0.1, 1, 2 μLのジュースがそれぞれ確率0.3, 0.6, 0.1で出るとします (Extended Data Fig.1と同じような分布にしています)。なお、著者らはシミュレーションとマウスに対してVariable-magnitude task (異なる量の報酬(ジュース)が異なる確率で出る)とVariable-probability task (一定量の報酬がある確率で出る)を行っています。以下はVariable-magnitude taskを行う、ということです。学習結果は次図のようになります。左はGround Truthの報酬分布で、右は$V_i$に対してカーネル密度推定 (KDE)することによって得た予測価値分布です。2つの分布はほぼ一致していることが分かります。 . #collapse-hide response_func = lambda r: np.sign(r) # RPEの応答関数 juice_amounts = np.array([0.1, 1, 2]) # reward(ジュース)の量(uL) juice_probs = np.array([0.3, 0.6, 0.1]) # 各ジュースが出る確率 num_cells = 200 # ニューロン(ユニット)の数 num_steps = 25000 # 訓練回数 base_lrate = 0.02 # ベースラインの学習率 distribution = np.zeros(num_cells) # 価値分布を記録する配列 alpha_pos = np.random.random(size=(num_cells)) # RPEが正のときの学習率 alpha_neg = np.random.random(size=(num_cells)) # RPEが負のときの学習率 tau = alpha_pos / (alpha_pos + alpha_neg) # Asymmetric scaling factor ############## # simulation # ############## for step in tqdm(range(num_steps)): # 25000 steps # 報酬がrandomに選ばれる reward = (np.random.choice(juice_amounts, p=juice_probs)) #(1, ) # 報酬誤差(step毎に更新) reward応答をlinearとする delta = reward - distribution # (200, ) # deltaが負なら1, 正なら0 valence = np.array(delta &lt;= 0., dtype=np.float32) # (200, ) # 予測価値分布の更新 alpha = valence * alpha_neg + (1. - valence) * alpha_pos distribution += alpha* response_func(delta) * base_lrate # tauの大きさでソートする ind = np.argsort(tau) tau = tau[ind] alpha_pos = alpha_pos[ind] alpha_neg = alpha_neg[ind] distribution = distribution[ind] ################ # Results plot # ################ # 報酬をサンプリング rewards = (np.random.choice(juice_amounts,size=1000, p=juice_probs)) # 結果の描画(価値・報酬分布) plt.figure(figsize=(8,4)) plt.subplot(1,2,1) # Ground Truth (Reward分布) plt.title(&quot;Reward distribution&quot;) sns.rugplot(rewards, color=&#39;k&#39;, lw=2, zorder=10) sns.kdeplot(rewards, bw=.15, color=&#39;k&#39;, lw=1., shade=True) plt.xlabel(&quot;Reward&quot;) plt.ylabel(&quot;Density&quot;) plt.subplot(1,2,2) # 学習後のValue(Reward)の分布 plt.title(&quot;Learned Value distribution&quot;) sns.kdeplot(distribution, bw=.15, color=&#39;k&#39;, lw=1., shade=True) sns.rugplot(distribution, color=&#39;k&#39;, lw=2, zorder=10) plt.xlabel(&quot;Value&quot;) plt.ylabel(&quot;Density&quot;) plt.tight_layout() plt.show() . . 100%|█████████████████████████████████████████████████████████████████████████| 25000/25000 [00:00&lt;00:00, 31986.89it/s] . そして$V_i$の経験累積分布関数(CDF)は$r$のサンプリングしたCDFとほぼ同一となっています (下図左)。また、$ tau_i$の関数である$V_i$は分位点関数 (quantile function)または累積分布関数の逆関数 (inverse cumulative distribution function)となっています (下図右)。右の図を転置すると左の青い曲線とだいたい一致しそうなことが分かります。 . #collapse-hide # 結果の描画(累積分布) plt.figure(figsize=(8,4)) plt.subplot(1,2,1) # 累積分布 sns.kdeplot(distribution, cumulative=True,bw=.05, label=&quot;Learned Value&quot;) sns.kdeplot(rewards, cumulative=True, bw=.05, label=&quot;Reward (GT)&quot;) plt.xlabel(&quot;Reward (Learned Value)&quot;) plt.ylabel(&quot;Cumulative probability&quot;) plt.subplot(1,2,2) # 累積分布 plt.plot(tau, distribution) plt.xlabel(&quot;Asymmetric scaling factors (&quot;+ r&quot;$ tau$)&quot;) plt.ylabel(&quot;Learned Value&quot;) plt.tight_layout() plt.show() . . sign&#38306;&#25968;&#12434;&#29992;&#12356;&#12383;Distributional RL&#12392;&#20998;&#20301;&#28857;&#22238;&#24112; . それでは、なぜ予測価値 $V_i$は$ tau_i$ 分位点に収束するのでしょうか。Extended Data Fig.1のように平衡点で考えてもよいのですが、後のために分位点回帰との関連について説明します。分位点回帰については記事を書いたので先にそちらを読んでもらうと分かりやすいと思います (→Pythonによる分位点回帰 (Quantile regression))。 . 実はDistributional RL (かつ、RPEの応答関数にsign関数を用いた場合)における予測報酬 $V_i$の更新式は、分位点回帰(Quantile regression)を勾配法で行うときの更新式とほとんど同じです。分位点回帰では$ delta$の関数$ rho_{ tau}( delta)$を次のように定義します。 $$ rho_{ tau}( delta)= left| tau- mathbb{I}_{ delta leq 0} right| cdot | delta|= left( tau- mathbb{I}_{ delta leq 0} right) cdot delta $$ そして、この関数を最小化することで回帰を行います。ここで$ tau$は分位点です。また$ delta=r-V$としておきます。今回、どんな行動をしても未来の報酬に影響はないので$ gamma=0$としています。 ここで、 $$ frac{ partial rho_{ tau}( delta)}{ partial delta}= rho_{ tau}^{ prime}( delta)= left| tau- mathbb{I}_{ delta leq 0} right| cdot operatorname{sign}( delta) $$ なので、$r$を観測値とすると、 $$ frac{ partial rho_{ tau}( delta)}{ partial V}= frac{ partial rho_{ tau}( delta)}{ partial delta} frac{ partial delta(V)}{ partial V}=- left| tau- mathbb{I}_{ delta leq 0} right| cdot operatorname{sign}( delta) $$ となります。ゆえに$V$の更新式は $$ V leftarrow V - beta cdot frac{ partial rho_{ tau}( delta)}{ partial V}=V+ beta left| tau- mathbb{I}_{ delta leq 0} right| cdot operatorname{sign}( delta) $$ です。ただし、$ beta$はベースラインの学習率です。個々の$V_i$について考え、符号で場合分けをすると $$ begin{cases} V_{i} leftarrow V_{i}+ beta cdot | tau_i| cdot operatorname{sign} left( delta_{i} right) &amp; text { for } delta_{i}&gt;0 V_{i} leftarrow V_{i}+ beta cdot | tau_i-1| cdot operatorname{sign} left( delta_{i} right) &amp; text { for } delta_{i} leq 0 end{cases} $$ となります。$0 leq tau_i leq 1$であり、$ tau_i= alpha_{i}^{+} / left( alpha_{i}^{+} + alpha_{i}^{-} right)$であることに注意すると上式は次のように書けます。 $$ begin{cases} V_{i} leftarrow V_{i}+ beta cdot frac{ alpha_{i}^{+}}{ alpha_{i}^{+}+ alpha_{i}^{-}} cdot operatorname{sign} left( delta_{i} right) &amp; text { for } delta_{i}&gt;0 V_{i} leftarrow V_{i}+ beta cdot frac{ alpha_{i}^{-}}{ alpha_{i}^{+}+ alpha_{i}^{-}} cdot operatorname{sign} left( delta_{i} right) &amp; text { for } delta_{i} leq 0 end{cases} $$ これは前節で述べたDistributional RLの更新式とほぼ同じです。いくつか違う点もありますが、RPEが正の場合と負の場合に更新される値の比は同じとなっています。 . このようにRPEの応答関数にsign関数を用いた場合、報酬分布を上手く符号化することができます。しかし実際のドパミンニューロンはsign関数のような生理的に妥当でない応答はせず、RPEの大きさに応じた活動をします。そこで次節ではRPEの応答関数を線形にしたときの話をします。 . Expectile &#12514;&#12487;&#12523;&#12392;&#12489;&#12497;&#12511;&#12531;&#12491;&#12517;&#12540;&#12525;&#12531;&#12363;&#12425;&#12398;&#22577;&#37228;&#20998;&#24067;&#12398;Decoding . RPE&#12395;&#23550;&#12377;&#12427;&#24540;&#31572;&#12364;&#32218;&#24418;&#12394;&#12514;&#12487;&#12523;&#12392;Expectile&#22238;&#24112; . 節の最後で述べたようにドパミンニューロンの活動はsign関数ではなく線形な応答をする、とした方が生理学的に妥当です (発火率を表現するならば$f( delta)=c+ delta quad(c &gt; 0)$とした方が良いのでしょうが)。それでは予測価値の更新式を $$ begin{cases} V_{i}(x) leftarrow V_{i}(x)+ alpha_{i}^{+} delta_{i} &amp; text{for } delta_{i} gt 0 V_{i}(x) leftarrow V_{i}(x)+ alpha_{i}^{-} delta_{i} &amp; text{for } delta_{i} leq 0 end{cases} $$ とした場合は、分位点回帰ではなく何に対応するのでしょうか。結論から言えば、この場合はエクスペクタイル回帰(Expectile regression)と同じになります。そもそも、expectileというのは聞きなれないですが、expectileという用語自体はexpectationとquantileを合わせたような概念、というところから来ています。中央値(median)に対する分位数(quantile)が、平均(mean)あるいは期待値(expectation)に対するexpectileの関係と同じであると捉えると良いです。 もう少し言えば、前者は誤差のL1ノルム, 後者はL2ノルムの損失関数を最小化することにより得られます (cf. Quantile and Expectile Regressions)。 . 分位点回帰で用いた損失関数は$$ rho_{ tau}( delta)= left| tau- mathbb{I}_{ delta leq 0} right| cdot | delta|$$でしたが、最後の$| delta|$を$ delta^2$として、 $$ rho^E_{ tau}( delta)= left| tau- mathbb{I}_{ delta leq 0} right| cdot delta^2$$ とします。これを微分すれば $$ frac{ partial rho^E_{ tau}( delta)}{ partial delta}= rho_{ tau}^{E prime}( delta)=2 cdot left| tau- mathbb{I}_{ delta leq 0} right| cdot delta $$ となり、上記の予測価値の更新式がExpectile回帰の損失関数から導けることが分かります。 . &#22577;&#37228;&#20998;&#24067;&#12398;&#12487;&#12467;&#12540;&#12487;&#12451;&#12531;&#12464; (decoding) . それで、RPEの応答を線形とした場合は報酬分布を上手く学習できるのかという話ですが、実はRPEの応答をsign関数とした場合と同じように学習後の予測価値の分布を求めても報酬分布は復元されません (簡単な修正で確認できます)。そこで報酬分布をデコーディングする方法を考えます。 . デコーデイングには各細胞が学習した予測価値(またはreversal points) $V_i$, asymmetries $ tau_i$, および報酬分布(ただし報酬の下限と上限からの一様分布)からのサンプル $z_m (m=1,2, cdots, M)$を用います。$N$を推定する$V_i$の数、$M=100$を1つの報酬サンプル集合$ {z_m }$内の要素数としたとき、次の損失関数を最小にする集合$ {z_m }$を求めます。 $$ mathcal{L}(z, V, tau)= frac{1}{M} sum_{m-1}^{M} sum_{n=1}^{N} left| tau_{n}- mathbb{I}_{z_{m} leq V_{n}} right| left(z_{m}-V_{n} right)^{2} $$ ここで、集合$ {z_m }$は20000回サンプリングするとします。損失関数$ mathcal{L}$を最小化する集合の分布が推定された報酬分布となっているので、それをplotします。以下はその結果とコードです (このコードはほとんど著者実装のままです)。灰色が元の報酬分布で、紫がデコーデイングされた分布です。完全とはいきませんが、ある程度は推定できていることが分かります。 . #collapse-hide import scipy.stats import scipy.optimize def expectile_loss_fn(expectiles, taus, samples): &quot;&quot;&quot;Expectile loss function, corresponds to distributional TD model &quot;&quot;&quot; # distributional TD model: delta_t = (r + gamma V*) - V_i # expectile loss: delta = sample - expectile delta = (samples[None, :] - expectiles[:, None]) # distributional TD model: alpha^+ delta if delta &gt; 0, alpha^- delta otherwise # expectile loss: |taus - I_{delta &lt;= 0}| * delta^2 # Note: When used to decode we take the gradient of this loss, # and then evaluate the mean-squared gradient. That is because *samples* must # trade-off errors with all expectiles to zero out the gradient of the # expectile loss. indic = np.array(delta &lt;= 0., dtype=np.float32) grad = -0.5 * np.abs(taus[:, None] - indic) * delta return np.mean(np.square(np.mean(grad, axis=-1))) def run_decoding(reversal_points, taus, minv=0., maxv=1., method=None, max_samples=1000, max_epochs=10, M=100): &quot;&quot;&quot;Run decoding given reversal points and asymmetries (taus).&quot;&quot;&quot; # sort ind = list(np.argsort(reversal_points)) points = reversal_points[ind] tau = taus[ind] # Robustified optimization to infer distribution # Generate max_epochs sets of samples, # each starting the optimization at the best of max_samples initial points. sampled_dist = [] for _ in range(max_epochs): # Randomly search for good initial conditions # This significantly improves the minima found samples = np.random.uniform(minv, maxv, size=(max_samples, M)) fvalues = np.array([expectile_loss_fn(points, tau, x0) for x0 in samples]) # Perform loss minimizing on expectile loss (w.r.t samples) x0 = np.array(sorted(samples[fvalues.argmin()])) fn_to_minimize = lambda x: expectile_loss_fn(points, tau, x) result = scipy.optimize.minimize( fn_to_minimize, method=method, bounds=[(minv, maxv) for _ in x0], x0=x0)[&#39;x&#39;] sampled_dist.extend(result.tolist()) return sampled_dist, expectile_loss_fn(points, tau, np.array(sampled_dist)) # reward distribution juice_amounts = np.array([0.1, 0.3, 1.2, 2.5, 5, 10, 20]) juice_empirical_probs = np.array( [0.06612594, 0.09090909, 0.14847358, 0.15489467, 0.31159175, 0.1509519 , 0.07705306]) # samples of reward (1000, ) sampled_empirical_dist = np.random.choice( juice_amounts, p=juice_empirical_probs, size=1000) n_trials = 10 # num of simulation trial n_epochs = 20000 # num of simulation epoch num_cells = 151 # num of cells or units n_decodings = 5 # num of decodings # Global scale for learning rates beta = 0.2 # Distributional TD simulation and decoding distribution = np.zeros((n_trials, num_cells)) alpha_pos = np.random.random((num_cells))*beta alpha_neg = np.random.random((num_cells))*beta # alpha_neg = beta - alpha_pos としてもよい # Simulation for trial in tqdm(range(n_trials)): for step in range(n_epochs): # Sample reward reward = np.random.choice(juice_amounts, p=juice_empirical_probs) # Compute TD error delta = reward - distribution[trial] # Update distributional value estimate valence = np.array(delta &lt;= 0., dtype=np.float32) alpha = valence * alpha_neg + (1. - valence) * alpha_pos distribution[trial] += alpha * delta # Decoding from distributional TD (DTD) simulation dtd_samples = [] # dtd_losses = [] # decoding loss taus = alpha_pos / (alpha_pos + alpha_neg) asym_variance = 0.2 for t in tqdm(range(n_decodings)): # Add noise to the scaling, but have mean 0.5 giving symmetric updates scaling_noise = np.tanh(np.random.normal(size=len(taus))) * asym_variance noisy_tau = np.clip(taus + scaling_noise, 0., 1.) # add noise # Run decoding for distributional TD values = run_decoding( distribution.mean(0), noisy_tau, minv=juice_amounts.min(), maxv=juice_amounts.max(), max_epochs=1, M=100, max_samples=20000, method=&#39;TNC&#39;) dtd_samples.append(values[0]) dtd_losses.append(values[1]) # print(t, values[1]) # results of decoding dtd_reward_decode = np.array(dtd_samples).flatten() # plot fig = plt.figure(figsize=(8, 5)) # Ground truth sns.kdeplot(sampled_empirical_dist, bw=.75, color=&#39;k&#39;, lw=0., shade=True) sns.rugplot(sampled_empirical_dist, color=&quot;red&quot;, lw=2, zorder=10, label=&quot;Empirical&quot;) # decoded distribution sns.kdeplot(dtd_reward_decode, bw=.75, color=plt.cm.plasma(0), lw=4., zorder=5, shade=False) sns.rugplot(dtd_reward_decode, color=plt.cm.plasma(0), label=&#39;Decoded&#39;) for draw in dtd_samples: sns.kdeplot(draw, bw=.5, color=plt.cm.plasma(0.), alpha=.5, lw=1., shade=False) plt.tick_params(top=False, right=False, labelsize=14) plt.legend(loc=&#39;best&#39;, fontsize=16) plt.xlabel(&quot;Reward&quot;, fontsize=16) plt.ylabel(&quot;Density&quot;, fontsize=16) plt.title(&quot;Distributional TD Decoding&quot;, fontsize=18) plt.tight_layout() plt.show() . . 100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05&lt;00:00, 1.81it/s] 100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:33&lt;00:00, 6.69s/it] . このようにしてRPEに対する応答が線形であるとした場合でも報酬分布を推定できました。同じことを著者らはドパミンニューロンの活動に対しても行い、報酬分布がデコーデイングされることを示しています。ただ、デコーデイングの手間が結構かかっている気がするので、学習した予測価値分布を利用するときにはどのような処理をしているのかは気になります。 . &#21442;&#32771;&#25991;&#29486; . Dabney, W., Kurth-Nelson, Z., Uchida, N. et al. A distributional code for value in dopamine-based reinforcement learning. Nature (2020). https://doi.org/10.1038/s41586-019-1924-6 | Watabe-Uchida, M. et al. Whole-Brain Mapping of Direct Inputs to Midbrain Dopamine Neurons. Neuron 74, 5, 858 - 873 (2012). https://doi.org/10.1016/j.neuron.2012.03.01700281-4) 00281-4) | Eshel, N., Tian, J., Bukwich, M. et al. Dopamine neurons share common response function for reward prediction error. Nat Neurosci 19, 479–486 (2016). https://doi.org/10.1038/nn.4239 | Schultz, W., Dayan, P., Montague, P.R. A neural substrate of prediction and reward. Science. 275, 1593-9 (1997). doi:10.1126/science.275.5306.1593 | Chang, C., Esber, G., Marrero-Garcia, Y. et al. Brief optogenetic inhibition of dopamine neurons mimics endogenous negative reward prediction errors. Nat Neurosci 19, 111–116 (2016) doi:10.1038/nn.4191 | Bayer, H.M., Lau, B., Glimcher, P.W. Statistics of midbrain dopamine neuron spike trains in the awake primate. J Neurophysiol. 98(3):1428-39 (2007). https://doi.org/10.1152/jn.01140.2006 | Eshel, N., Bukwich, M., Rao, V. et al. Arithmetic and local circuitry underlying dopamine prediction errors. Nature 525, 243–246 (2015). https://doi.org/10.1038/nature14855 | .",
            "url": "https://salad-bowl-of-knowledge.github.io/hp/neuroscience/2020/01/20/drl.html",
            "relUrl": "/neuroscience/2020/01/20/drl.html",
            "date": " • Jan 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "NibabelとMayaviによるMR画像の可視化",
            "content": "PythonでNifti (The Neuroimaging Informatics Technology Initiative) 形式のMR画像の可視化をしてみる。まずNifti (nii.gz)形式のファイルはNibabelでloadする。Nibabelはpipで入る：pip install nibabel . なお、Nibabelに依存した機械学習ライブラリとしてNilearnというのもある。今回は使わない。 . Nibabel tutorial . NibabelのtutorialにはEPI法(echo planar imaging)で撮影された拡散強調像 (someones_epi.nii.gz) と、(恐らく)T1 強調像 (someones_anatomy.nii.gz) の2つのデータが用意されている。どちらでもよいが、someones_anatomy.nii.gzの方をダウンロードしておく。 . nibabelの関数(nib.load)でデータを読み込み、matplotlibで可視化する。 . import nibabel as nib import numpy as np import matplotlib.pyplot as plt from matplotlib import gridspec # Data load img = nib.load(&#39;someones_anatomy.nii.gz&#39;) img_data = img.get_fdata() print(img_data.shape) # (57, 67, 56) # Plot gs = gridspec.GridSpec(1, 3, width_ratios=[1.17, 1, 1.17]) plt.figure(figsize=(8,4)) plt.subplot(gs[0]) plt.title(&quot;Sagittal&quot;) plt.imshow(np.flipud(img_data[28].T), cmap=&quot;gray&quot;) plt.subplot(gs[1]) plt.title(&quot;Coronal&quot;) plt.imshow(np.flipud(img_data[:, 33].T), cmap=&quot;gray&quot;) plt.subplot(gs[2]) plt.title(&quot;Horizontal&quot;) plt.imshow(img_data[:, :, 28], cmap=&quot;gray&quot;) plt.tight_layout() plt.show() . . マーモセット脳MRIデータセット . マーモセット(marmoset)脳のMRIデータセット (Marmoset Brain Mapping)が公開された[1, 2]ので、それを読み込んで可視化してみる。 . まず、dataのページから150um dMRIの前処理後のデータ(DTI-Fitted)をダウンロードする。これを選んでいるのは単にデータサイズが小さいため。このデータはマーモセットから脳を取り出した後、ホルマリン固定後、gadoliniumに浸して造影し、7T MRIでスキャンすることで得られたものである。 . zipファイルを解凍後、DTIFIT_FA.nii.gzというデータ (添え字の詳細が無かった)を読み込んで可視化する。 . Nibabelによるマーモセット脳MRIの断面図の可視化 . コード自体は先ほどのtutorialのものとほぼ同じ。 . import nibabel as nib import numpy as np import matplotlib.pyplot as plt from matplotlib import gridspec # Data load img = nib.load(&#39;DTIFIT_FA.nii.gz&#39;) img_data = img.get_fdata() print(img_data.shape) # (192, 256, 192) # Plot gs = gridspec.GridSpec(1, 3, width_ratios=[1.33, 1, 1.33]) plt.figure(figsize=(10,4)) plt.subplot(gs[0]) plt.title(&quot;Sagittal&quot;) plt.imshow(np.flipud(img_data[96].T), cmap=&quot;gray_r&quot;) plt.subplot(gs[1]) plt.title(&quot;Coronal&quot;) plt.imshow(np.flipud(img_data[:, 128].T), cmap=&quot;gray_r&quot;) plt.subplot(gs[2]) plt.title(&quot;Horizontal&quot;) plt.imshow(img_data[:, :, 96], cmap=&quot;gray_r&quot;) plt.tight_layout() plt.show() . . Mayaviによるマーモセット脳の3Dでの可視化 . Pythonで3次元Plotをするのにはmatplotlibやplotlyなどもあるが、今回はMayaviを用いる。installはpip install mayaviでできるが、 . $ git clone https://github.com/enthought/mayavi.git $ cd mayavi $ pip install -r requirements.txt $ pip install PyQt5 # replace this with any supported toolkit $ python setup.py install # or develop . をすると確実。 . import nibabel as nib from mayavi import mlab img = nib.load(&#39;DTIFIT_FA.nii.gz&#39;) img_data = img.get_fdata() fig = mlab.figure(size=(400, 400), bgcolor = (1,1,1)) src = mlab.pipeline.scalar_field(img_data) mlab.pipeline.iso_surface(src, contours=[img_data.min()+0.05*img_data.ptp(), ], opacity=1, color=(.5, .5, .5)) mlab.show() . . 実際にはグリグリと3Dで脳を動かしてみることができる。なお、脳溝がほぼ見えないが、マーモセットは元々脳溝が少ない。 . 参考文献 . Liu, C., Ye, F.Q., Newman, J.D. et al. A resource for the detailed 3D mapping of white matter pathways in the marmoset brain. Nat Neurosci. (2020) doi:10.1038/s41593-019-0575-0 | Liu, C., Ye, F. Q., Yen, C. C., Newman, J. D. et al. A digital 3D atlas of the marmoset brain based on multi-modal MRI. NeuroImage. (2018). doi:10.1016/j.neuroimage.2017.12.004 | .",
            "url": "https://salad-bowl-of-knowledge.github.io/hp/neuroscience/2020/01/15/nibabel.html",
            "relUrl": "/neuroscience/2020/01/15/nibabel.html",
            "date": " • Jan 15, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://salad-bowl-of-knowledge.github.io/hp/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "CIELUV色相環をPythonで描画する",
            "content": "CIE Luv色空間 (CIE 1976 Luv color space)の色相環(hue wheel)をOpenCVとMatplotlibで描画する。 . ぶっちゃけると色覚に関する研究もしていて、JNNS2019でポスター発表はしたが頓挫したりあっちこっちに行ったりしている。今回はその付随したメモである。色空間について、自分は今までHSV色空間を使うなどかなり適当だったが、先行研究がほとんどCIELUV色空間を使っていたので調べることとした。単なるHSVでは色の数値的差が知覚的差と一致しないが、CIELuvでは両者ができるだけ近くなるようにしている。 . 描画にはcolourまたはOpenCVを使う。Pythonのpackageであるcolourはpipで入る：pip install colour-science . なお、変換をscratchでする場合にはhttp://www.easyrgb.com/en/math.phpが参考になる。 . OpenCV&#12434;&#20351;&#12358;&#22580;&#21512; . CIE Luv色空間において値域はL [0, 100], u[-100, 100], v[-100, 100]である。Hue angle の配列を作り、cos, sinに入れて100をかけ、それぞれをu, vとする。そしてLを適当に定めることでLuvの配列ができる。 . 後の面倒な変換はcv2.cvtColor(hogehoge, cv2.COLOR_Luv2RGB)に任せる(cf. 変換できる色空間の一覧)。単なる変換ではRGBのどれかの値が負の値を取るが、それを0にclippingしている。逆にcvtColorを使うと正規化されずにclippingされるので、L=100のときはほぼ白色となる。 . 変換式は下記参照（Miscellaneous Image Transformations — OpenCV 2.4.13.7 documentationより引用）。 . . &#33394;&#30456;&#12496;&#12540; . import matplotlib.pyplot as plt import numpy as np import cv2 N_theta = 1000 luv = np.zeros((1, N_theta, 3)).astype(np.float32) theta = np.linspace(0, 2*np.pi, N_theta) luv[:, :, 0] = 80 # L luv[:, :, 1] = np.cos(theta)*100 # u luv[:, :, 2] = np.sin(theta)*100 # v rgb = cv2.cvtColor(luv, cv2.COLOR_Luv2RGB) plt.imshow(rgb, vmin=0, vmax=1, aspect=100) plt.show() . &#33394;&#30456;&#29872; . N_theta = 1000 luv = np.zeros((1, N_theta, 3)).astype(np.float32) theta = np.linspace(0, 2*np.pi, N_theta) luv[:, :, 0] = 80 # L luv[:, :, 1] = np.cos(theta)*100 # u luv[:, :, 2] = np.sin(theta)*100 # v rgb = cv2.cvtColor(luv, cv2.COLOR_Luv2RGB) # hue wheel plot ax = plt.subplot(111, polar=True) #get coordinates: theta = np.linspace(0, 2*np.pi, rgb.shape[1]+1) r = np.linspace(0.5, 1, rgb.shape[0]+1) Theta,R = np.meshgrid(theta, r) # get color color = rgb.reshape((rgb.shape[0]*rgb.shape[1], rgb.shape[2])) m = plt.pcolormesh(theta,R, rgb[:,:,0], color=color, linewidth=0) # This is necessary to let the `color` argument determine the color m.set_array(None) plt.show() . uv&#24179;&#38754; . uv平面をplotすると次のようになる。 . W = 1000 H = 1000 luv = np.zeros((W, H, 3)).astype(np.float32) u = np.linspace(-100, 100, W) # u v = np.linspace(-100, 100, H) # v U, V = np.meshgrid(u, v) luv[:, :, 0] = 80 luv[:, :, 1] = U luv[:, :, 2] = V RGB = cv2.cvtColor(luv, cv2.COLOR_Luv2RGB) plt.figure(figsize=(5,5)) plt.imshow(RGB, vmin=0, vmax=1) plt.show() . Colour&#12434;&#20351;&#12358;&#22580;&#21512; . colourは色の変換関数が充実している。そこでu&#39;, v&#39;平面上の円周上の色を、xyに変換、さらにXYZに変換し(このときY=1とする)、最後にRGBに変換したものをplotする。 . &#33394;&#30456;&#12496;&#12540; . HSVと比べると青がかなり短いことが分かる。 . import colour N_theta = 500 theta = np.linspace(0, 2*np.pi, N_theta) r = 0.2 u = np.cos(theta)*r + 0.2009 v = np.sin(theta)*r + 0.4610 uv = np.dstack((u, v)) # map -&gt; xy -&gt; XYZ -&gt; sRGB xy = colour.Luv_uv_to_xy(uv) xyz = colour.xy_to_XYZ(xy) rgb = colour.XYZ_to_sRGB(xyz) rgb = colour.utilities.normalise_maximum(rgb, axis=-1) plt.figure(figsize=(5,3)) plt.imshow(np.reshape(rgb, (1, N_theta, 3)), aspect=100) plt.show() . N_theta = 500 theta = np.linspace(0, 2*np.pi, N_theta) r = 0.2 u = np.cos(theta)*r + 0.2009 v = np.sin(theta)*r + 0.4610 uv = np.dstack((u, v)) # map -&gt; xy -&gt; XYZ -&gt; sRGB xy = colour.Luv_uv_to_xy(uv) xyz = colour.xy_to_XYZ(xy) rgb = colour.XYZ_to_sRGB(xyz) rgb = colour.utilities.normalise_maximum(rgb, axis=-1) # hue wheel plot ax = plt.subplot(111, polar=True) #get coordinates: theta = np.linspace(0, 2*np.pi, rgb.shape[1]+1) r = np.linspace(0.5, 1, rgb.shape[0]+1) Theta,R = np.meshgrid(theta, r) # get color color = rgb.reshape((rgb.shape[0]*rgb.shape[1], rgb.shape[2])) m = plt.pcolormesh(theta,R, rgb[:,:,0], color=color, linewidth=0) # This is necessary to let the `color` argument determine the color m.set_array(None) plt.show() . CIE 1976 UCS (uniform chromaticity scale) diagram . 描画方法を2つ示す。 . Method 1 . 黒線は光のスペクトルに対応する点を意味する。 . import matplotlib.pyplot as plt import numpy as np import colour samples = 258 xlim = (0, 1) ylim = (0, 1) wvl = np.arange(420, 700, 5) wvl_XYZ = colour.wavelength_to_XYZ(wvl) wvl_uv = colour.Luv_to_uv(colour.XYZ_to_Luv(wvl_XYZ)) wvl_pts = wvl_uv * samples u = np.linspace(xlim[0], xlim[1], samples) v = np.linspace(ylim[0], ylim[1], samples) uu, vv = np.meshgrid(u, v) # stack u and v for vectorized computations uuvv = np.stack((vv,uu), axis=2) # map -&gt; xy -&gt; XYZ -&gt; sRGB xy = colour.Luv_uv_to_xy(uuvv) xyz = colour.xy_to_XYZ(xy) dat = colour.XYZ_to_sRGB(xyz) dat = colour.normalise_maximum(dat, axis=-1) # now make an alpha/transparency mask to hide the background # and flip u,v axes because of column-major symantics alpha = np.ones((samples, samples)) # * wvl_mask dat = np.swapaxes(np.dstack((dat, alpha)), 0, 1) # lastly, duplicate the lowest wavelength so that the boundary line is closed wvl_uv = np.vstack((wvl_uv, wvl_uv[0,:])) fig, ax = plt.subplots(figsize=(5,5)) ax.imshow(dat, extent=[xlim[0], xlim[1], ylim[0], ylim[1]], interpolation=&#39;None&#39;, origin=&#39;lower&#39;) ax.set(xlim=(0, 0.7), xlabel=&#39;CIE u &#39;&#39;, ylim=(0, 0.7), ylabel=&#39;CIE v &#39;&#39;) ax.plot(wvl_uv[:,0], wvl_uv[:,1], c=&#39;0&#39;, lw=3) plt.show() . Method 2 . colour.plottingを用いる方法。 . import colour.plotting as cpl cpl.plot_chromaticity_diagram_CIE1976UCS(standalone=False) cpl.render( standalone=True, bounding_box=(-0.1, 0.7, -0.05, 0.7), x_tighten=True, y_tighten=True, filename=&quot;CIE1976UCS_diagram.png&quot;) plt.show() .",
            "url": "https://salad-bowl-of-knowledge.github.io/hp/python/2020/01/13/cieluv.html",
            "relUrl": "/python/2020/01/13/cieluv.html",
            "date": " • Jan 13, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "scGenの解説",
            "content": "概要 . scGenの論文の解説．実際はほぼVAEの話になった．実験の詳細とかは割愛．LPSが異なる生物に与える影響とかを予測していてかなりアツい． . 細胞が外界から刺激を受けたときにどんな反応をするかを予測する．潜在空間で摂動$ delta$が加えられたときに，遺伝子発現空間での変化をニューラルネットワークを使って予測する． . VAE 　 . variational autoencoder(VAE)では確率分布$P( boldsymbol{x}_i; boldsymbol{ theta})$に従って新しいデータ点が生成される．ただし，確率分布は$P( boldsymbol{x}_i; boldsymbol{ theta})$の対数尤度（を各$ boldsymbol{x}_i$について足したもの）が最大となるように取る．潜在変数を$ boldsymbol{z}$とすれば，この確率は次のようになる： begin{aligned} P( boldsymbol{x}_i; boldsymbol{ theta})= int P( boldsymbol{x}_i| boldsymbol{z}_i; boldsymbol{ theta})P( boldsymbol{z}_i; boldsymbol{ theta}) ,d boldsymbol{z}_i. end{alined} $ boldsymbol{x}_i$を生成しそうな$ boldsymbol{z}_i$が潜在空間から正規分布$P( boldsymbol{z}_i; boldsymbol{ theta})$に従ってサンプリングされるような確率分布を求めることが目標になる． . ここで，$P( boldsymbol{x}_i| boldsymbol{z}_i; boldsymbol{ theta})$に近い確率分布$Q( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ theta})$をニューラルネットワークで作る．２つの確率分布の近さの評価としてKullback Leibler divergenceを使う： begin{equation} begin{split} &amp; text{KL}(Q( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ phi}) |P( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ theta})) &amp;= E_{Q( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ phi})} left[ log Q( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ phi})- log P( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ theta}) right] &amp;= E_{Q( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ phi})} Bigl[ log Q( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ phi})- log frac{P( boldsymbol{z}_i; boldsymbol{ theta})}{P( boldsymbol{x}_i; boldsymbol{ theta})}P( boldsymbol{x}_i| boldsymbol{z}_i; boldsymbol{ theta}) Bigr] &amp;= E_{Q( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ phi})} bigl[ log Q( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ phi})- log P( boldsymbol{z}_i; boldsymbol{ theta})- log P( boldsymbol{x}_i| boldsymbol{z}_i; boldsymbol{ theta})+ log P( boldsymbol{x}_i; boldsymbol{ theta}) bigr] &amp;= -E_{Q( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ phi})}[ log P( boldsymbol{x}_i| boldsymbol{z}_i; boldsymbol{ theta})]+ log P( boldsymbol{x}_i; boldsymbol{ theta})+ text{KL}(Q( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ phi}) | P( boldsymbol{z}_i; boldsymbol{ theta})). end{split} end{equation} 式変形の途中でBayesの定理を用いた．$Q( boldsymbol{z}_i| boldsymbol{x}_i; boldsymbol{ theta})$は$P( boldsymbol{x}_i| boldsymbol{z}_i; boldsymbol{ theta})$の近似であるので，これらの量のKullback Leibler divergenceはほぼ$0$である．よって， .",
            "url": "https://salad-bowl-of-knowledge.github.io/hp/single-cell-analysis/2019/10/02/scgen.html",
            "relUrl": "/single-cell-analysis/2019/10/02/scgen.html",
            "date": " • Oct 2, 2019"
        }
        
    
  
    
        ,"post8": {
            "title": "グリッド細胞の発火パターンをPythonで可視化する",
            "content": "&#27010;&#35201; . Edvard Moser博士の研究室が公開している、グリッド細胞の活動をPythonで可視化してみました。データはhttps://www.ntnu.edu/kavli/research/grid-cell-dataからダウンロードできます。 . コードを書く上でhttp://felix11h.github.io/blog/grid-cell-rate-mapsを参考にしました。一部の関数はこのブログから引用しています。今回は上記のサイトで実装されていない、Gaussian kernelを用いたSmoothed rate mapとAutocorrelation mapの実装をしてみます。 . Important: 著者はGrid cellsの研究をしていません。実際の研究で用いられるコードと異なる可能性があります。 . &#12464;&#12522;&#12483;&#12489;&#32048;&#32990;(Grid Cells)&#12395;&#12388;&#12356;&#12390; . 実装とは関係ないですが、グリッド細胞についてまとめておきます。 . &#31354;&#38291;&#22522;&#24213;&#12392;&#12375;&#12390;&#12398;&#12464;&#12522;&#12483;&#12489;&#32048;&#32990; . 詳しくは場所細胞 - 脳科学辞典や2014年のノーベル生理学・医学賞の解説（神経科学学会）、Grid cells (Scholarpedia)などをお読みいただければと思います。簡単にまとめると、海馬には場所特異的に発火する場所細胞(place cell)があり、これはO&#39;keefe博士によって発見されました。次にMay-Britt Moser博士とEdvard Moser博士は六角形格子状の場所受容野を持つグリッド細胞(格子細胞, grid cell)を内側嗅内皮質(medial entorhinal cortex; MEC)で発見しました。この3人は2014年のノーベル生理学・医学賞を受賞しています。 . . http://www.scholarpedia.org/article/Grid_cellsより。左図の黒線はラットの経路、赤は発火が生じた位置。右図は発火率マップ(rate map)。 . 最近、外側膝状体背側核(dorsal lateral geniculate nucleus)で場所細胞が見つかったそうです（V Hok, et al., 2018, bioRxiv）。 . &#12487;&#12540;&#12479;&#12395;&#12388;&#12356;&#12390; . 公開されているデータはMatLabのmatファイル形式です。しかし、scipy.io.loadmatを用いることでpythonでデータの中身を取得することができます。 . 使用するデータは以下の通りです。 . 10704-07070407_POS.mat | 10704-07070407_T2C3.mat | . これらのファイルはhttps://archive.norstore.no/pages/public/datasetDetail.jsf?id=8F6BE356-3277-475C-87B1-C7A977632DA7からダウンロードできるファイルの一部です。ただし全体で2.23GBあるので、簡単に試したい場合は上記のリンクからダウンロードしてください。以下では./data/grid_cells_data/ディレクトリの下にファイルを置いています。 . データの末尾の&quot;POS&quot;と&quot;T2C3&quot;の意味について説明しておきます。まず、&quot;POS&quot;はpost, posx, posyを含む構造体でそれぞれ試行の経過時間、x座標, y座標です。座標は-50~50で記録されています。恐らく1m四方の正方形の部屋で、原点を部屋の中心としているのだと思います。&quot;T2C3&quot;はtがtetrode（テトロード電極）でcがcell（細胞）を意味します。後ろの数字は番号付けたものと思われます。 . Smoothed Rate Map&#12395;&#12388;&#12356;&#12390; . 発火率$ lambda( boldsymbol{x})$は、場所$ boldsymbol{x}=(x,y)$で記録されたスパイクの回数を、場所$ boldsymbol{x}$における滞在時間(s)で割ることで得られます。 $$ lambda( boldsymbol{x})= frac{ displaystyle sum_{i=1}^n g left( frac{ boldsymbol{s}_i- boldsymbol{x}}{h} right)}{ displaystyle int_0^T g left( frac{ boldsymbol{y}(t)- boldsymbol{x}}{h} right)dt} $$ ただし、$n$はスパイクの回数、$T$は計測時間、$g( cdot)$はGaussain Kernel（中身の分子が平均、分母が標準偏差）、$ boldsymbol{s}_i$は$i$番目のスパイクの発生した位置、$ boldsymbol{y}(t)$は時刻$t$でのラットの位置です。分母は積分になっていますが、実際には離散的に記録をするので、累積和に変更し、$dt$を時間のステップ幅(今回は0.02s)とします。 . Gaussian Kernelを用いて平滑化することで「10cm四方での発火を同じ位置での発火とする」などとした場合よりも、得られるマップは滑らかになります。 . &#23455;&#35013; . まず、ライブラリをインポートしてデータを読み込みます。 . import numpy as np import matplotlib.pyplot as plt from scipy import io as io from tqdm import tqdm # from http://www.ntnu.edu/kavli/research/grid-cell-data pos = io.loadmat(&#39;./data/grid_cells_data/10704-07070407_POS.mat&#39;) spk = io.loadmat(&#39;./data/grid_cells_data/10704-07070407_T2C3.mat&#39;) . posファイル内の構造は次のようになっています。 . pos[&quot;post&quot;]: times at which positions were recorded | pos[&quot;posx&quot;]: x positions | pos[&quot;posy&quot;]: y positions | spk[&quot;cellTS&quot;]: spike times | . 次に種々の関数を実装します。 . def nearest_pos(array, value): k = (np.abs(array - value)).argmin() return k . def GaussianKernel(sizex, sizey, sigma=0.5, center=None): &quot;&quot;&quot; sizex : kernel width sizey : kernel height sigma : gaussian Sd center : gaussian mean return gaussian kernel &quot;&quot;&quot; x = np.arange(0, sizex, 1, float) y = np.arange(0, sizey, 1, float) x, y = np.meshgrid(x,y) if center is None: x0 = sizex // 2 y0 = sizey // 2 else: if np.isnan(center[0])==False and np.isnan(center[1])==False: x0 = center[0] y0 = center[1] else: return np.zeros((sizey,sizex)) return np.exp(-((x-x0)**2 + (y-y0)**2) / 2*sigma**2) . def smoothed_rate_map(pos, spk, kernel_sigma=0.1, W=100, H=100): # load datas posx = pos[&quot;posx&quot;].flatten() posy = pos[&quot;posy&quot;].flatten() spkt = spk[&quot;cellTS&quot;].flatten() #change positions range: -50 ~ 50 -&gt; 0 ~ H or W posx = (posx + 50) / 100 * W posy = (posy + 50) / 100 * H # find nearest positions when spikes occur indx = [nearest_pos(pos[&quot;post&quot;],t) for t in spkt] indy = [nearest_pos(pos[&quot;post&quot;],t) for t in spkt] # occup position while trajectory occup_m_list = [] for i in tqdm(range(len(posx))): occup_m_list.append(GaussianKernel(W, H, kernel_sigma, (posx[i], posy[i]))) occup_m = sum(occup_m_list) occup_m *= 0.02 # one time step is 0.02s occup_m[occup_m==0] = 1 # avoid devide by zero # activation activ_m_list = [] for i in tqdm(range(len(spkt))): activ_m_list.append(GaussianKernel(W, H, kernel_sigma, (posx[indx][i] ,posy[indy][i]))) activ_m = sum(activ_m_list) rate_map = activ_m / occup_m return rate_map . 最後に実行します。 . rm = smoothed_rate_map(pos, spk, 0.2, 100, 100) plt.figure(figsize=(6,4)) plt.imshow(rm, cmap=&quot;jet&quot;) plt.colorbar(label=&quot;Hz&quot;) plt.gca().invert_yaxis() plt.tight_layout() # plt.savefig(&quot;smoothed_rate_map.png&quot;) plt.show() . 100%|██████████████████████████████████████████████████████████████████████████| 30000/30000 [00:09&lt;00:00, 3306.34it/s] 100%|█████████████████████████████████████████████████████████████████████████████| 2326/2326 [00:02&lt;00:00, 959.91it/s] . Autocorrelation Map&#12395;&#12388;&#12356;&#12390; . https://core.ac.uk/download/pdf/30859910.pdfのSupporting Online Materialに書いてある式通りに実装してみましたが、遅い＆論文と見た目が全く異なるので、scipy.signal.correlate2dを使いました。 . from scipy.signal import correlate2d rm = smoothed_rate_map(pos, spk, 0.5, 100, 100) a_corr = correlate2d(rm, rm, fillvalue=5) plt.figure(figsize=(6,4)) plt.imshow(a_corr, cmap=&quot;jet&quot;) plt.colorbar(label=&quot;Autocorrelation&quot;) plt.tight_layout() # plt.savefig(&quot;autocorr.png&quot;) plt.show() . 100%|██████████████████████████████████████████████████████████████████████████| 30000/30000 [00:16&lt;00:00, 1795.03it/s] 100%|█████████████████████████████████████████████████████████████████████████████| 2326/2326 [00:02&lt;00:00, 929.87it/s] . 若干論文と図が異なる上、cross-correlationが-1~1の範囲でないのはおかしい気がするのですが、六角形格子が見えているので良しとします。 . &#21442;&#32771;&#12395;&#12375;&#12383;&#25991;&#29486;&#12539;&#12469;&#12452;&#12488; . https://github.com/Felix11H/grid_cell_rate_map | https://www.ntnu.edu/kavli/research/grid-cell-data | https://core.ac.uk/download/pdf/30859910.pdfのSupporting Online Material | https://github.com/MattNolanLab/gridcells | https://arxiv.org/pdf/1810.07429.pdf | .",
            "url": "https://salad-bowl-of-knowledge.github.io/hp/neuroscience/2018/11/23/grid_cells.html",
            "relUrl": "/neuroscience/2018/11/23/grid_cells.html",
            "date": " • Nov 23, 2018"
        }
        
    
  

  
  
      ,"page0": {
          "title": "About Us",
          "content": "山拓：神経科学の研究をしています。 Github : https://github.com/takyamamoto | 凪：理学部（）と工学部（）がいるので人間科学部（）になってみる今日このごろ | ざっきぃ：ライフワークはクラシック音楽鑑賞。しばらく統計から離れて医学に集中します。 | 優曇華院：数理物理学者． | みこ：音楽バカ。医者になるのはフルートを吹くため | .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page1": {
          "title": "神経科学",
          "content": "神経表現の可視化 . グリッド細胞の発火パターンをPythonで可視化する | スパイクトリガー平均・共分散の計算法 (Python) | ネコLGN細胞のスパイクトリガー平均による受容野解析 | Sorted plotの注意点 | . 解剖・形態学 . NibabelとMayaviによるMR画像の可視化 | 脳が対側支配をする進化的な利点は何か | . 色覚 . RGBからXYZ, LMS色空間への変換 | CIELUV色相環をPythonで描画する | . 強化学習 . Distributional Reinforcement Learningの仕組み | . 計算神経科学 . 古典的モデル . FitzHugh-Nagumoモデルをアニメーションで見る | Hodgkin-Huxleyモデルをアニメーションで見る | 心臓刺激伝導系の数理モデルのPythonでのシミュレーション | . ニューラルネットワークと神経科学 . 予測符号化 (predictive coding) とは何か | 掛け算のニューラルネットワークとベイズ推定 | 『人工神経回路で脳を理解する』論文まとめ | ニューラルネットワークにおける意味発達の数学理論 | Spiking Neural UnitをChainerで実装してみた | 物体認識のためのRecurrent CNNまとめ | FORCE法によるRecurrent Spiking Neural Networksの教師あり学習 | 人工神経回路による脳の理解はどこまで進んだか | . Computational neuroscience (Coursera) . Computational neuroscience : Week0 | Computational neuroscience : Week1 | Computational neuroscience : Week2 | Computational neuroscience : Week3 | .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/neuroscience/",
          "relUrl": "/neuroscience/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "機械学習",
          "content": "最適化 . [線形計画法（シンプレックス法）入門　PDFファイル] | Hamiltonian Descent Methodsの実装についての解説 | Boltzmann Generatorsの解説 | . Deep Learning . Chainer . Chainerで学習率のスケジューリングをする方法 | ChainerでPredNetの実装をしてみた | . TensorFlow . tensorflow-gpuとCUDAのバージョン | . Keras . Kerasにおける中間層の出力の可視化 | KerasによるGraph Convolutional Networks | Kerasにおいてforループでmodelを定義する | Keras examples directoryで実装例を見る | KerasのconvLSTM2Dの使用例を見る | . 強化学習 . OpenAI Gymでオリジナルの環境を作る | Kerasを用いたDQNでFlappyBirdを学習させる | .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/machine-learning/",
          "relUrl": "/machine-learning/",
          "date": ""
      }
      
  

  
      ,"page3": {
          "title": "統計学",
          "content": "Pythonで統計処理 . 分散共分散行列を相関行列/偏相関係数に変換 | Graph Lassoによる変数間の関係のグラフ化 | Pythonで線形回帰モデルの計算（１） | Pythonで線形回帰モデルの計算（２） | Pythonで正規分布の区間推定 | PythonでGaussian Fitting | scipyによる1次元混合ガウス回帰 | matplotlibのみで線形回帰の信頼区間を描画する | matplotlibで棒グラフ間の有意差の描画をする | Pythonによる分位点回帰 (Quantile regression) | . 確率論 . 確率モデル . 確率過程とランダムウォーク | マルコフ連鎖 (Markov chain) | . 確率分布 . q分位数と中央値 | 確率変数の変換 | デルタ法 (Delta method) | . 統計的推定・検定 . 比率の区間推定 | ノンパラメトリック検定 | ケンドールの一致係数(Kendall’s coefficient of concordance) | . 統計解析 . 回帰分析 . 重回帰分析① | 重回帰分析② | 正規方程式 | ロジスティック回帰分析 | 対数オッズ比の分散 | . データ分析 . Principle Curve 入門 | PythonによるPrincipal Curveの実装 (bendingアルゴリズム) | . 稲垣宣生 「数理統計学」演習問題の解答 . 書いたものをあげます。 . 演習問題1 | 演習問題2 | 演習問題3 | 演習問題4 | 演習問題5 | 演習問題6 | 演習問題7 | 演習問題8 | 演習問題9 | 演習問題10 | 演習問題11 | 演習問題12 | 演習問題13 | 演習問題14 | . 統計検定 . 統計検定2級のフィードバック（前編） | 統計検定2級のフィードバック（後編） | .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/statistics/",
          "relUrl": "/statistics/",
          "date": ""
      }
      
  

  
      ,"page4": {
          "title": "医学",
          "content": "生理学 . 心臓震盪とリミットサイクル | . 薬理学 . コンパートメントモデル(薬物動態)のシミュレーション | . 環境医学・公衆衛生学 . 疫学基礎 | . 医用工学 . PET検査の仕組み（第1回）「PETの基礎理論」 | PET検査の仕組み（第2回）「画像再構成①：Radon変換」 | PET検査の仕組み（第3回）「画像再構成②：逆Radon変換」 | PET検査の仕組み（第4回）「画像再構成③：FBP法」 | PET検査の仕組み（第5回）「誤差要因の補正(1)：偶発同時計数と散乱同時計数」 | PET検査の仕組み（第6回）「誤差要因の補正(2)：吸収と感度の補正」 | PET検査の仕組み（第7回）「PETシミュレーション」 | 脳波と脳磁図 (PDFファイル) | . シングルセル解析 . scEpathの解説 | Palantirの解説 | scGenの解説 | . 医学知識の整理 . 大学の試験対策用に作成したデータを、学問別に公開しようと思う。初学者が、各学問の全貌を大雑把に把握するのに適していると思う。 . メモ帳というアプリで毎回作っているため、基本的には図がない。ビジュアル面は、自身の参考書などで補ってほしい。 . 組織学 . 骨 | 神経 | 血液 | 心血管系 | 呼吸器系 | 食道・胃 | 肝・胆・膵 | 小腸・大腸 | 口腔（歯・舌・唾液腺） | 内分泌系１ | 内分泌系２ | 泌尿器系 | 眼・耳 | . 生理学 . 細胞の一般生理 | 膜電位と興奮 | シナプス | 筋生理 | 血液生理 | 呼吸 | 循環１ | 循環２ | 循環３ | 末梢神経・自律神経 | . 生物科学（Essential細胞生物学11～16章） . 遺伝学（Essential細胞生物学5～10章） . 解剖学 . 神経解剖学 .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/medicine/",
          "relUrl": "/medicine/",
          "date": ""
      }
      
  

  
      ,"page5": {
          "title": "化学",
          "content": "化学 .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/chemistry/",
          "relUrl": "/chemistry/",
          "date": ""
      }
      
  

  
      ,"page6": {
          "title": "物理学",
          "content": "物理学 .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/physics/",
          "relUrl": "/physics/",
          "date": ""
      }
      
  

  
      ,"page7": {
          "title": "数学",
          "content": "数学 .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/mathematics/",
          "relUrl": "/mathematics/",
          "date": ""
      }
      
  

  
      ,"page8": {
          "title": "Programming",
          "content": "Programming .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/programming/",
          "relUrl": "/programming/",
          "date": ""
      }
      
  

  
      ,"page9": {
          "title": "Computer",
          "content": "Computer .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/computer/",
          "relUrl": "/computer/",
          "date": ""
      }
      
  

  
      ,"page10": {
          "title": "読書",
          "content": "読書 .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/reading/",
          "relUrl": "/reading/",
          "date": ""
      }
      
  

  
      ,"page11": {
          "title": "エッセイ",
          "content": "エッセイ .",
          "url": "https://salad-bowl-of-knowledge.github.io/hp/essay/",
          "relUrl": "/essay/",
          "date": ""
      }
      
  

  

  

  
  

  

  
  

  

  
  

  
  

}