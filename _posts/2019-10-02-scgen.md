---
toc: true
layout: post
description:
author: 優曇華院
categories: [single-cell-analysis]
title: scGenの解説
---

## 概要
[scGenの論文](https://www.nature.com/articles/s41592-019-0494-8)の解説．実際はほぼVAEの話になった．実験の詳細とかは割愛．LPSが異なる生物に与える影響とかを予測していてかなりアツい．

細胞が外界から刺激を受けたときにどんな反応をするかを予測する．潜在空間で摂動$\delta$が加えられたときに，遺伝子発現空間での変化をニューラルネットワークを使って予測する．

## VAE    　
variational autoencoder(VAE)では確率分布$P(\boldsymbol{x}_i;\boldsymbol{\theta})$に従って新しいデータ点が生成される．ただし，確率分布は$P(\boldsymbol{x}_i;\boldsymbol{\theta})$の対数尤度（を各$\boldsymbol{x}_i$について足したもの）が最大となるように取る．潜在変数を$\boldsymbol{z}$とすれば，この確率は次のようになる：
$$
\begin{aligned}
P(\boldsymbol{x}_i;\boldsymbol{\theta})=\int P(\boldsymbol{x}_i| \boldsymbol{z}_i;\boldsymbol{\theta})P(\boldsymbol{z}_i;\boldsymbol{\theta})\,d\boldsymbol{z}_i.
\end{aligned}
$$
$\boldsymbol{x}_i$を生成しそうな$\boldsymbol{z}_i$が潜在空間から正規分布$P(\boldsymbol{z}_i;\boldsymbol{\theta})$に従ってサンプリングされるような確率分布を求めることが目標になる．

ここで，$P(\boldsymbol{x}_i| \boldsymbol{z}_i;\boldsymbol{\theta})$に近い確率分布$Q(\boldsymbol{z}_i| \boldsymbol{x}_i;\boldsymbol{\theta})$をニューラルネットワークで作る．２つの確率分布の近さの評価としてKullback Leibler divergenceを使う：
$$
\begin{aligned}
\begin{split} &\text{KL}(Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})\|P(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\theta}))\\
&= E_{Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})}\left[\log Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})-\log P(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\theta})\right]\\
&= E_{Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})}\Bigl[\log
Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})-\log\frac{P(\boldsymbol{z}_i;\boldsymbol{\theta})}{P(\boldsymbol{x}_i;\boldsymbol{\theta})}P(\boldsymbol{x}_i|\boldsymbol{z}_i;\boldsymbol{\theta})\Bigr]\\
&= E_{Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})}\bigl[\log Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})-\log P(\boldsymbol{z}_i;\boldsymbol{\theta})-\log
P(\boldsymbol{x}_i|\boldsymbol{z}_i;\boldsymbol{\theta})+\log P(\boldsymbol{x}_i;\boldsymbol{\theta})\bigr]\\ &= -E_{Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})}[\log
P(\boldsymbol{x}_i|\boldsymbol{z}_i;\boldsymbol{\theta})]+\log P(\boldsymbol{x}_i;\boldsymbol{\theta})+\text{KL}(Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})\|
P(\boldsymbol{z}_i;\boldsymbol{\theta})). \end{split}
\end{aligned}
$$
式変形の途中でBayesの定理を用いた．$Q(\boldsymbol{z}_i| \boldsymbol{x}_i;\boldsymbol{\theta})$は$P(\boldsymbol{x}_i|
\boldsymbol{z}_i;\boldsymbol{\theta})$の近似であるので，これらの量のKullback Leibler divergenceはほぼ$0$である．よって，
