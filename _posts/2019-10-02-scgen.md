---
toc: true
layout: post
description:
author: 優曇華院
categories: [single-cell-analysis]
title: scGenの解説
---

## 概要
[scGenの論文](https://www.nature.com/articles/s41592-019-0494-8)の解説．実際はほぼVAEの話になった．実験の詳細とかは割愛．LPSが異なる生物に与える影響とかを予測していてかなりアツい．

細胞が外界から刺激を受けたときにどんな反応をするかを予測する．潜在空間で摂動$\delta$が加えられたときに，遺伝子発現空間での変化をニューラルネットワークを使って予測する．

## VAE    　
variational autoencoder(VAE)では確率分布$P(\boldsymbol{x}_i;\boldsymbol{\theta})$に従って新しいデータ点が生成される．ただし，確率分布は$P(\boldsymbol{x}_i;\boldsymbol{\theta})$の対数尤度（を各$\boldsymbol{x}_i$について足したもの）が最大となるように取る．潜在変数を$\boldsymbol{z}$とすれば，この確率は次のようになる：

$$
P(\boldsymbol{x}_i;\boldsymbol{\theta})=\int P(\boldsymbol{x}_i\mid\boldsymbol{z}_i;\boldsymbol{\theta})P(\boldsymbol{z}_i;\boldsymbol{\theta})\,d\boldsymbol{z}_i.
$$

$\boldsymbol{x}_i$を生成しそうな$\boldsymbol{z}_i$が潜在空間から正規分布$P(\boldsymbol{z}_i;\boldsymbol{\theta})$に従ってサンプリングされるような確率分布を求めることが目標になる．

ここで，$P(\boldsymbol{x}_i \mid \boldsymbol{z}_i;\boldsymbol{\theta})$ に近い確率分布 $Q(\boldsymbol{z}_i\mid \boldsymbol{x}_i;\boldsymbol{\theta})$ をニューラルネットワークで作る．
２つの確率分布の近さの評価としてKullback Leibler divergenceを使う：

$$
\begin{aligned}
&\text{KL}(Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})\|P(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\theta}))\\
&= E_{Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})}\left[\log Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})-\log P(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\theta})\right]\\
&= E_{Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})}\Bigl[\log
Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})-\log\frac{P(\boldsymbol{z}_i;\boldsymbol{\theta})}{P(\boldsymbol{x}_i;\boldsymbol{\theta})}P(\boldsymbol{x}_i|\boldsymbol{z}_i;\boldsymbol{\theta})\Bigr]\\
&= E_{Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})}\bigl[\log Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})-\log P(\boldsymbol{z}_i;\boldsymbol{\theta})-\log
P(\boldsymbol{x}_i|\boldsymbol{z}_i;\boldsymbol{\theta})+\log P(\boldsymbol{x}_i;\boldsymbol{\theta})\bigr]\\ &= -E_{Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})}[\log
P(\boldsymbol{x}_i|\boldsymbol{z}_i;\boldsymbol{\theta})]+\log P(\boldsymbol{x}_i;\boldsymbol{\theta})+\text{KL}(Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})\|
P(\boldsymbol{z}_i;\boldsymbol{\theta})).
\end{aligned}
$$

式変形の途中でBayesの定理を用いた．$Q(\boldsymbol{z}_i\mid\boldsymbol{x}_i;\boldsymbol{\theta})$は$P(\boldsymbol{x}_i|
\boldsymbol{z}_i;\boldsymbol{\theta})$の近似であるので，これらの量のKullback Leibler divergenceはほぼ$0$である．よって，

$$
\begin{aligned} \log P(\boldsymbol{x}_i;\boldsymbol{\theta})\simeq
 E_{Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})}[\log P(\boldsymbol{x}_i|\boldsymbol{z}_i;\boldsymbol{\theta})] \text{KL}(Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})\|
P(\boldsymbol{z}_i;\boldsymbol{\theta})).\label{ELBO}
\end{aligned}
$$
<!---
$\eqref{ELBO}$第１項は解析的に解くことは困難なので，Monte Carlo法によるサンプリングによって決める．ただし，$Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})$に従って$\boldsymbol{z}_i$を選び出す：
$$
\begin{aligned} \boldsymbol{z}_i\sim
    Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi}) \end{aligned}
$$
のは不便であるので，再パラメータ化を考える．すなわち，
$$
\begin{aligned} \boldsymbol{z}_i = g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon},
    \boldsymbol{x}_i),\quad \boldsymbol{\epsilon}\sim p(\boldsymbol{\epsilon}) \end{aligned}
$$
となる関数$g_{\boldsymbol{\phi}}$とノイズ$\boldsymbol{\epsilon}$を適当に選んでやる．こうすれば，

$$
\begin{aligned}
    E_{Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})}[f(\boldsymbol{z}_i)] &= \int Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi}) f(\boldsymbol{z}_i)d\boldsymbol{z}_i\\ &=
    \int p(\boldsymbol{\epsilon}) f(\boldsymbol{z}_i)d\boldsymbol{\epsilon}\\ &= E_{p(\boldsymbol{\epsilon})}[f(\boldsymbol{z}_i)],\quad \boldsymbol{z}_i =
    g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon}, \boldsymbol{x}_i)  \end{aligned}
$$
となる．よって，再パラメータ化を施せば$\eqref{ELBO}$第１項は
$$
\begin{aligned}
    E_{Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})}[\log P(\boldsymbol{x}_i|\boldsymbol{z}_i;\boldsymbol{\theta})] &= \frac{1}{L}\sum_{l=1}^L\log
    P(\boldsymbol{x}_i|\boldsymbol{z}_i{}^{(l)};\boldsymbol{\theta}) \end{aligned}
$$
となる．ただし，
$$
\begin{aligned} \boldsymbol{z}_i{}^{(l)}=g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon}^{(l)},
    \boldsymbol{x}_i),\quad \boldsymbol{\epsilon}^{(l)}\sim p(\boldsymbol{\epsilon}) \end{aligned}
$$
である．よって，$\eqref{ELBO}$は次のようになる：
$$
\begin{aligned} \log
    P(\boldsymbol{x}_i;\boldsymbol{\theta})=\frac{1}{L}\sum_{l=1}^L\log
    P(\boldsymbol{x}_i|\boldsymbol{z}_i{}^{(l)};\boldsymbol{\theta})-\text{KL}(Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})\\midP(\boldsymbol{z}_i;\boldsymbol{\theta})).
    \label{ELBO_Monte_Carlo} \end{aligned}
$$
ここで，$Q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\theta})$が多変量正規分布であると仮定する：
$$
\begin{aligned}
    Q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\theta})=\frac{1}{\sqrt{(2\pi)^n|\Sigma|}}\exp\left[-\frac{1}{2}{}^t(\boldsymbol{z}-\boldsymbol\mu)\Sigma{}^{-1}(\boldsymbol{z}-\boldsymbol\mu)\right].
    \end{aligned}
$$
ただし，$\Sigma,\boldsymbol\mu$は$\boldsymbol{x}$によって決まり，特に$\Sigma$は対角行列であるとする：
$$
\begin{aligned} \Sigma = \begin{pmatrix} \sigma_1{}^2 &&&O\\ & \sigma_2{}^2 &&\\
&&\ddots&\\ O &&& \sigma_n{}^2 \end{pmatrix}. \end{aligned}   
$$
さらに，$P(\boldsymbol{z};\boldsymbol{\theta})$も正規分布であるとする：
$$
\begin{aligned} P(\boldsymbol{z};\boldsymbol{\theta}) =
    \frac{1}{\sqrt{(2\pi)^n}}\exp\left(-\frac{|\boldsymbol{z}|^2}{2}\right). \end{aligned}
$$
まず，
$$
\begin{aligned}  \int Q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\theta})\log
    P(\boldsymbol{z};\boldsymbol{\theta})\,d\boldsymbol{z} &=
    \frac{1}{\sqrt{(2\pi)^n|\Sigma|}}\int\exp\left[-\frac{1}{2}{}^t(\boldsymbol{z}-\boldsymbol\mu)\Sigma{}^{-1}(\boldsymbol{z}-\boldsymbol\mu)\right]\left[-\frac{n}{2}\log(2\pi)-\frac{|\boldsymbol{z}|^2}{2}\right]\,d\boldsymbol{z}\\
    &=
    -\frac{n}{2}\log(2\pi)-\frac{1}{2\sqrt{(2\pi)^n|\Sigma|}}\int|\boldsymbol{z}|^2\exp\left[-\frac{1}{2}{}^t(\boldsymbol{z}-\boldsymbol\mu)\Sigma{}^{-1}(\boldsymbol{z}-\boldsymbol\mu)\right]\,d\boldsymbol{z}
     \end{aligned}
$$
第２項の積分は
$$
\begin{aligned}  \sum_{i=1}^n\int z_i{}^2\exp\left[-\frac{1}{2}\sum_{j=1}^n\frac{(z_j-\mu_{j})^2}{\sigma_j{}^2}\right]\,d\boldsymbol{z}&=\sum_{i=1}^n\int
    \exp\left[-\frac{(z_1-\mu_{1})^2}{2\sigma_1{}^2}\right]\,dz_1\times\dots\times\int z_i{}^2\exp\left[-\frac{(z_j-\mu_{j})^2}{2\sigma_j{}^2}\right]\,dz_i\times\dots\times\int
    \exp\left[-\frac{(z_n-\mu_{n})^2}{2\sigma_n{}^2}\right]\,dz_n\\ &= \sum_{i=1}^n(2\pi)^{\frac{n-1}{2}}\prod_{j\neq i}\sigma_j\int
    z_i{}^2\exp\left[-\frac{(z_j-\mu_{j})^2}{2\sigma_j{}^2}\right]\,dz_i\\ &= \sum_{i=1}^n(2\pi)^{\frac{n}{2}}\prod_{j=1}^n\sigma_j(\sigma_i{}^2+\mu_{i}{}^2)  \end{aligned}
$$
のように変形できるので，
$$
\begin{aligned} \int Q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\theta})\log P(\boldsymbol{z};\boldsymbol{\theta})\,d\boldsymbol{z}=
    -\frac{n}{2}\log(2\pi)-\frac{1}{2}\sum_{i=1}^n(\sigma_i{}^2+\mu_{i}{}^2). \label{KL_1} \end{aligned}
$$
次に，
$$
\begin{aligned}  \int Q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\theta})\log
    Q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\theta})\,d\boldsymbol{z}&=\frac{1}{\sqrt{(2\pi)^n|\Sigma|}}\int\exp\left[-\frac{1}{2}\sum_{i=1}^n\frac{(z_i-\mu_{i})^2}{\sigma_i{}^2}\right]\left[-\frac{n}{2}\log
    2\pi-\frac{1}{2}\log|\Sigma|-\frac{1}{2}\sum_{j=1}^n\frac{(z_j-\mu_{j})^2}{\sigma_j{}^2}\right]\,d\boldsymbol{z}\\ &=-\frac{n}{2}\log
    2\pi-\frac{1}{2}\log|\Sigma|-\frac{1}{2\sqrt{(2\pi)^n|\Sigma|}}\sum_{i=1}^n\int\frac{(z_i-\mu_{i})^2}{\sigma_i{}^2}\exp\left[-\sum_{j=1}^n\frac{(z_j-\mu_{j})^2}{2\sigma_j{}^2}\right]\,d\boldsymbol{z}
     \end{aligned}
$$
第３項の積分は
$$
\begin{aligned}  \sum_{i=1}^n\frac{1}{{\sigma_i}^2}\int z_i{}^2\prod_{j=1}^n\exp\left(-\frac{z_j{}^2}{2\sigma_j{}^2}\right)\,d\boldsymbol{z}&=
    \sum_{i=1}^n\frac{1}{{\sigma_i}^2}\int\exp\left(-\frac{z_1{}^2}{2\sigma_1{}^2}\right)\,dz_1\times\dots\times\int
    z_i{}^2\exp\left(-\frac{z_i{}^2}{2\sigma_i{}^2}\right)\,dz_i\times\dots\times\int\exp\left(-\frac{z_n{}^2}{2\sigma_n{}^2}\right)\,dz_n\\
    &=\sum_{i=1}^n\frac{1}{{\sigma_i}^2}(2\pi)^{\frac{n-1}{2}}\prod_{j\neq i}\sigma_j\sqrt{2\pi}\sigma_i{}^3\\ &=\sum_{i=1}^n (2\pi)^{\frac{n}{2}}\prod_{j=1}^n\sigma_j  \end{aligned}
$$
のように変形できるので，
$$
\begin{aligned} \int Q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\theta})\log
  Q(\boldsymbol{z}|\boldsymbol{x};\boldsymbol{\theta})\,d\boldsymbol{z}=-\frac{n}{2}\log(2\pi)-\frac{1}{2}\sum_{j=1}^n(1+\log\sigma_j{}^2). \label{KL_2} \end{aligned}
$$
$\eqref{KL_1}$，$\eqref{KL_2}$から，$\eqref{ELBO}$第２項は，
$$
\begin{aligned}  -\text{KL}(Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})\\midP(\boldsymbol{z}_i;\boldsymbol{\theta})) &= -\int
    Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\theta})\log Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\theta})\,d\boldsymbol{z}_i+\int
    Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\theta})\log P(\boldsymbol{z}_i;\boldsymbol{\theta})\,d\boldsymbol{z}_i\\ &=
    \frac{1}{2}\sum_{j=1}^n[(1+\log{\sigma_j}^2)-\mu_j{}^2-\sigma_j{}^2].  \end{aligned}
$$

また，今回は$Q(\boldsymbol{z}_i|\boldsymbol{x}_i;\boldsymbol{\phi})$が正規分布$\mathcal{N}(\boldsymbol{z}_i,\boldsymbol{\mu},\boldsymbol{\sigma}\odot\boldsymbol{\sigma}E)$であるとしたので，再パラメータ化は
$$
\begin{aligned}
    g_{\boldsymbol{\phi}}(\boldsymbol{\epsilon},\boldsymbol{x}_i) =
    \boldsymbol{\mu}(\boldsymbol{x}_i)+\boldsymbol{\sigma}(\boldsymbol{x}_i)\odot\boldsymbol{\epsilon},\quad\boldsymbol{\epsilon}\sim\mathcal{N}(\boldsymbol{\epsilon},0,E) \end{aligned}
$$
とする．これは，
$$
\begin{aligned} E_{\mathcal{N}(\boldsymbol{\epsilon},0,E)}[\boldsymbol{\mu}(\boldsymbol{x}_i)+\boldsymbol{\sigma}(\boldsymbol{x}_i)\odot\boldsymbol{\epsilon}]=\boldsymbol{\mu}(\boldsymbol{x}_i)
\end{aligned}
$$
および
$$
\begin{aligned} E_{\mathcal{N}(\boldsymbol{\epsilon},0,E)}[(\mu_i+\sigma_i\epsilon_i-\mu_i)(\mu_j+\sigma_j\epsilon_j-\mu_j)]= \delta_{ij}\sigma_i\sigma_j \end{aligned}
$$
から分かる．

以上から，
$$
\begin{aligned} \log P(\boldsymbol{x}_i;\boldsymbol{\theta}) = \frac{1}{2}\sum_{j=1}^n[(1+\log{\sigma_j}^2)-\mu_j{}^2-\sigma_j{}^2]+\frac{1}{L}\sum_{l=1}^L\log
    P(\boldsymbol{x}_i|\boldsymbol{z}_i{}^{(l)};\boldsymbol{\theta}). \end{aligned}
$$
ただし，
$$
\begin{aligned}  \boldsymbol{z}_i{}^{(l)}&=
    \boldsymbol{\mu}^{(l)}(\boldsymbol{x}_i)+\boldsymbol{\sigma}^{(l)}(\boldsymbol{x}_i)\odot\boldsymbol{\epsilon}^{(l)},\\ \boldsymbol{\epsilon}^{(l)}&\sim\mathcal{N}(\boldsymbol{\epsilon},0,E).
     \end{aligned}
$$
これが最大になるように，NNを構成すればよい．


## 摂動 $\delta$ の予想
各状態にある細胞を抽出し，細胞の数によるバイアスを無くすために，調節する．最後に

$$
\delta=\overline{z_1}-\overline{z_0}
$$

を計算する．$\overline{z_0}$は各状態の潜在変数の平均，$\overline{z_1}$は摂動があったときの潜在変数の平均．
--->
